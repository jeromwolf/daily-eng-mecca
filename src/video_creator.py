"""
MoviePyë¥¼ ì‚¬ìš©í•œ ìœ íŠœë¸Œ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë“ˆ (ë¡±í¼ 16:9 ê°€ë¡œ)
"""
import os
from pathlib import Path
from moviepy import (
    VideoClip, ImageClip, AudioFileClip, TextClip,
    CompositeVideoClip, CompositeAudioClip, concatenate_videoclips, ColorClip, vfx
)
from src.clips.quiz import (
    QuestionClip, CountdownClip, AnswerClip,
    ExplanationClip, ExampleClip
)
from src.preview import QuizPreviewGenerator
from src.config.kelly_dialogues import (
    get_random_intro, get_random_outro,
    get_random_quiz_intro, get_random_quiz_outro
)
from src.config.video_settings import VideoSettings


class VideoCreator:
    def __init__(self, image_generator=None, resource_manager=None, use_kelly=True):
        """VideoCreator ì´ˆê¸°í™”"""
        # VideoSettingsì—ì„œ ê°€ì ¸ì˜¤ê¸°
        self.width = VideoSettings.WIDTH  # 1920 (ê°€ë¡œ)
        self.height = VideoSettings.HEIGHT  # 1080 (ì„¸ë¡œ)
        self.fps = VideoSettings.FPS  # 30

        # Kelly ë ˆì´ì•„ì›ƒ ì„¤ì •
        self.kelly_width = VideoSettings.KELLY_WIDTH  # 640 (ì™¼ìª½ 1/3)
        self.content_width = VideoSettings.CONTENT_WIDTH  # 1280 (ì˜¤ë¥¸ìª½ 2/3)

        self.image_generator = image_generator
        self.resource_manager = resource_manager

        # Kelly Cat ìºë¦­í„° ì‚¬ìš© ì—¬ë¶€
        self.use_kelly = use_kelly

        # ì»¤ìŠ¤í…€ ì¸íŠ¸ë¡œ/ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ê²½ë¡œ (ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)
        self.intro_custom_image = None
        self.outro_custom_image = None

    def _get_kelly_image_path(self, kelly_type: str = "casual_hoodie") -> str:
        """
        Kelly ìºë¦­í„° ì´ë¯¸ì§€ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°

        Args:
            kelly_type: Kelly ì´ë¯¸ì§€ íƒ€ì… (casual_hoodie, ponytail, glasses)

        Returns:
            Kelly ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ None)
        """
        if not self.resource_manager:
            return None

        # Kelly ì´ë¯¸ì§€ íŒŒì¼ëª…
        kelly_filename = f"kelly_{kelly_type}.png"
        kelly_path = Path(self.resource_manager.resources_dir) / "images" / kelly_filename

        if kelly_path.exists():
            return str(kelly_path)

        print(f"âš ï¸ Kelly ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {kelly_path}")
        return None

    def create_video(
        self,
        sentences: list[str],
        image_paths: list[str],
        audio_info: list[dict],
        output_path: str,
        image_groups: list[list[int]] = None,
        translations: list[str] = None,
        hook_phrase: str = None
    ) -> str:
        """
        ìœ íŠœë¸Œ ì‡¼ì¸  ë¹„ë””ì˜¤ ìƒì„±

        Args:
            sentences: ì˜ì–´ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
            image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            audio_info: ê° ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ ì •ë³´ [{'path': str, 'duration': float}, ...]
            output_path: ë¹„ë””ì˜¤ ì €ì¥ ê²½ë¡œ
            image_groups: ê° ì´ë¯¸ì§€ì— í‘œì‹œí•  ë¬¸ì¥ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
            translations: í•œê¸€ ë²ˆì—­ ë¦¬ìŠ¤íŠ¸
            hook_phrase: ì¸íŠ¸ë¡œ í›… ë¬¸êµ¬ (AI ìë™ ìƒì„±, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)

        Returns:
            ìƒì„±ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        try:
            print("ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")

            # ê¸°ë³¸ ì´ë¯¸ì§€ ê·¸ë£¹ ì„¤ì • (ê° ë¬¸ì¥ì— í•˜ë‚˜ì”©)
            if image_groups is None:
                image_groups = [[i] for i in range(len(sentences))]

            # ì¸íŠ¸ë¡œ ìƒì„± (3ì´ˆ, í›… ë¬¸êµ¬ í¬í•¨)
            intro_clip = self._create_intro_clip(duration=3, hook_phrase=hook_phrase)

            # ê° ì´ë¯¸ì§€ì— ì–´ë–¤ ë¬¸ì¥ë“¤ì´ ë§¤í•‘ë˜ëŠ”ì§€ í™•ì¸
            # ê° ë¬¸ì¥ë§ˆë‹¤ ê°œë³„ í´ë¦½ì„ ìƒì„± (ì •í™•í•œ íƒ€ì´ë°ì„ ìœ„í•´)
            sentence_clips = []
            audio_clips = []

            # ë¬¸ì¥ ì¸ë±ìŠ¤ -> ì´ë¯¸ì§€ ê²½ë¡œ ë§¤í•‘ ìƒì„±
            sentence_to_image = {}
            for img_idx, sent_indices in enumerate(image_groups):
                for sent_idx in sent_indices:
                    if sent_idx < len(sentences) and img_idx < len(image_paths):
                        sentence_to_image[sent_idx] = image_paths[img_idx]

            # ê° ë¬¸ì¥ë§ˆë‹¤ ê°œë³„ í´ë¦½ ìƒì„± (TTSì™€ ì •í™•íˆ ë™ê¸°í™”)
            # ê° ë¬¸ì¥ì„ 3ë²ˆ ë°˜ë³µ (ê° ë°˜ë³µë§ˆë‹¤ ë‹¤ë¥¸ ìŒì„± ì‚¬ìš© - í•™ìŠµ íš¨ê³¼ í–¥ìƒ)
            current_time = 3.0  # ì¸íŠ¸ë¡œ 3ì´ˆ í›„ë¶€í„° ì‹œì‘
            pause_duration = 2.0  # ê° ë¬¸ì¥ ì‚¬ì´ ê°„ê²© (ì‚¬ìš©ìê°€ ë”°ë¼ ë§í•  ì‹œê°„)
            repeat_count = 3  # ê° ë¬¸ì¥ì„ 3ë²ˆ ë°˜ë³µ
            voices_list = ['alloy', 'nova', 'shimmer']  # ê° ë°˜ë³µë§ˆë‹¤ ë‹¤ë¥¸ ìŒì„±

            for repeat in range(repeat_count):
                current_voice = voices_list[repeat]
                print(f"\n=== {repeat + 1}íšŒì°¨ ë°˜ë³µ ({current_voice} ìŒì„±) ===")

                for sent_idx in range(len(sentences)):
                    if sent_idx >= len(audio_info):
                        continue

                    # í•´ë‹¹ ë¬¸ì¥ì˜ ì´ë¯¸ì§€
                    img_path = sentence_to_image.get(sent_idx, image_paths[0])

                    # í•´ë‹¹ ë¬¸ì¥ê³¼ ë²ˆì—­
                    sentence_text = sentences[sent_idx]
                    translation_text = translations[sent_idx] if translations and sent_idx < len(translations) else ""

                    # í•´ë‹¹ ë¬¸ì¥ì˜ ì˜¤ë””ì˜¤ duration + ê°„ê²© (í˜„ì¬ ìŒì„± ê¸°ì¤€)
                    audio_duration = audio_info[sent_idx]['voices'][current_voice]['duration']
                    clip_duration = audio_duration + pause_duration

                    print(f"  ë¬¸ì¥ {sent_idx + 1}: {audio_duration:.2f}ì´ˆ + ê°„ê²© {pause_duration}ì´ˆ = {clip_duration:.2f}ì´ˆ (ì‹œì‘: {current_time:.2f}ì´ˆ)")

                    # í´ë¦½ ìƒì„± (íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ TTS ë™ê¸°í™”)
                    clip = self._create_sentence_clip(
                        image_path=img_path,
                        sentences=[sentence_text],
                        translations=[translation_text] if translation_text else [],
                        duration=clip_duration,
                        start_time=0,
                        tts_duration=audio_duration  # TTS ê¸¸ì´ ì „ë‹¬ (íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ ë™ê¸°í™”)
                    )
                    sentence_clips.append(clip)

                    # ì˜¤ë””ì˜¤ í´ë¦½ ì¶”ê°€ (ì •í™•í•œ ì‹œì‘ ì‹œê°„ ì„¤ì •, í˜„ì¬ ìŒì„± ì‚¬ìš©)
                    audio_path = audio_info[sent_idx]['voices'][current_voice]['path']
                    audio_clip = AudioFileClip(audio_path).with_start(current_time)
                    audio_clips.append(audio_clip)

                    current_time += clip_duration

            # ì•„ì›ƒíŠ¸ë¡œ ìƒì„± (2ì´ˆ)
            outro_clip = self._create_outro_clip(duration=2)

            # ëª¨ë“  í´ë¦½ ì—°ê²°
            video_clips = [intro_clip] + sentence_clips + [outro_clip]
            final_video = concatenate_videoclips(video_clips, method="compose")

            # ì´ ë¹„ë””ì˜¤ ê¸¸ì´ í™•ì¸
            sentences_duration = sum(info['voices']['alloy']['duration'] for info in audio_info) * repeat_count + (pause_duration * len(audio_info) * repeat_count)
            total_duration = 3 + sentences_duration + 2
            print(f"\nì´ ë¹„ë””ì˜¤ ê¸¸ì´: {total_duration:.2f}ì´ˆ")
            print(f"  - ì¸íŠ¸ë¡œ: 3.00ì´ˆ")
            print(f"  - ë¬¸ì¥ë“¤: {sentences_duration:.2f}ì´ˆ (TTS + ê°„ê²© í¬í•¨, {repeat_count}íšŒ ë°˜ë³µ)")
            print(f"  - ì•„ì›ƒíŠ¸ë¡œ: 2.00ì´ˆ")

            # ì˜¤ë””ì˜¤ í´ë¦½ë“¤ì„ ì •í™•í•œ ì‹œì‘ ì‹œê°„ìœ¼ë¡œ í•©ì„±
            from moviepy import CompositeAudioClip
            combined_audio = CompositeAudioClip(audio_clips)

            # ë°°ê²½ ìŒì•… ì¶”ê°€ (ë‚®ì€ ë³¼ë¥¨, ì¸íŠ¸ë¡œ 3ì´ˆì—ë§Œ ì¬ìƒ)
            background_music_path = None
            if self.resource_manager:
                # resources í´ë”ì—ì„œ ë°°ê²½ ìŒì•… ì°¾ê¸° (original íŒŒì¼ ìš°ì„ )
                bg_music_candidates = [
                    os.path.join(str(self.resource_manager.resources_dir), "background_music_original.mp3"),
                    os.path.join(str(self.resource_manager.resources_dir), "background_music.mp3"),
                    os.path.join(str(self.resource_manager.resources_dir), "bgm.mp3"),
                ]
                for path in bg_music_candidates:
                    if os.path.exists(path):
                        background_music_path = path
                        break

            if background_music_path:
                try:
                    print(f"ë°°ê²½ ìŒì•… ì¶”ê°€: {background_music_path}")
                    bg_music = AudioFileClip(background_music_path)
                    print(f"  - ì›ë³¸ ìŒì•… ê¸¸ì´: {bg_music.duration:.2f}ì´ˆ")
                    print(f"  - ë¹„ë””ì˜¤ ê¸¸ì´: {total_duration:.2f}ì´ˆ")

                    # ë³¼ë¥¨ ë¨¼ì € ë‚®ì¶”ê¸° (5%) - ìˆœì„œ ì¤‘ìš”! (ë³¼ë¥¨ ë¨¼ì €, ìë¥´ê¸° ë‚˜ì¤‘)
                    bg_music = bg_music * 0.05
                    print(f"  - ë³¼ë¥¨ ì¡°ì ˆ ì™„ë£Œ: 5%")
                    print(f"  - ë³¼ë¥¨ ì¡°ì ˆ í›„ ê¸¸ì´: {bg_music.duration:.2f}ì´ˆ")

                    # ì¸íŠ¸ë¡œ 3ì´ˆë§Œ ì¬ìƒ (ë³¼ë¥¨ ì¡°ì • í›„ ìë¥´ê¸°)
                    intro_duration = 3.0
                    if bg_music.duration >= intro_duration:
                        # ì›ë³¸ íŒŒì¼ì˜ ì• 3ì´ˆë§Œ ìë¥´ê¸°
                        bg_music = bg_music.subclipped(0, intro_duration)
                        print(f"  - background_music_original.mp3ì˜ ì• {intro_duration:.2f}ì´ˆë§Œ ì¬ìƒ")
                    else:
                        # 3ì´ˆë³´ë‹¤ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        print(f"  - ë°°ê²½ ìŒì•… ê¸¸ì´ {bg_music.duration:.2f}ì´ˆ ê·¸ëŒ€ë¡œ ì‚¬ìš©")

                    print(f"  - ìµœì¢… ë°°ê²½ìŒì•… ê¸¸ì´: {bg_music.duration:.2f}ì´ˆ")

                    # ë°°ê²½ ìŒì•…ì„ ì‹œì‘(0ì´ˆ)ì— ë°°ì¹˜ - ì¸íŠ¸ë¡œì™€ ë™ì‹œ ì¬ìƒ
                    bg_music = bg_music.with_start(0)

                    # TTSì™€ ë°°ê²½ìŒì•… í•©ì„± (ë°°ê²½ìŒì•…ì€ ì¸íŠ¸ë¡œ 3ì´ˆì—ë§Œ ì¬ìƒ)
                    # with_duration ì œê±° - ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ê¸¸ì´ê°€ ì„¤ì •ë¨
                    combined_audio = CompositeAudioClip([combined_audio, bg_music])
                    print(f"âœ“ ë°°ê²½ ìŒì•… ì¶”ê°€ ì™„ë£Œ (ì¸íŠ¸ë¡œ {intro_duration:.2f}ì´ˆì—ë§Œ ì¬ìƒ)")
                    print(f"  - ìµœì¢… ì˜¤ë””ì˜¤ ê¸¸ì´: {combined_audio.duration:.2f}ì´ˆ")
                except Exception as e:
                    print(f"âš  ë°°ê²½ ìŒì•… ì¶”ê°€ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                    import traceback
                    traceback.print_exc()

            # ìŒì„± ì¶”ê°€ (ê° ì˜¤ë””ì˜¤ í´ë¦½ì€ ì´ë¯¸ ì •í™•í•œ ì‹œì‘ ì‹œê°„ì´ ì„¤ì •ë¨)
            final_video = final_video.with_audio(combined_audio)

            # ë¹„ë””ì˜¤ ì €ì¥
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            print(f"[DEBUG] write_videofile ì‹œì‘ (create_video): {output_path}")

            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True,
                preset='medium',
                logger='bar',  # í”„ë¡œê·¸ë ˆìŠ¤ ë°” í‘œì‹œ
                threads=4,     # ë©€í‹°ìŠ¤ë ˆë“œ (ì•ˆì •ì„± í–¥ìƒ)
                ffmpeg_params=['-max_muxing_queue_size', '9999']  # íŒŒì´í”„ ë²„í¼ ì¦ê°€ (Broken pipe ë°©ì§€)
            )

            print(f"[DEBUG] write_videofile ì™„ë£Œ")

            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            for audio_clip in audio_clips:
                audio_clip.close()
            combined_audio.close()
            final_video.close()

            print(f"âœ“ ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
            return output_path

        except BrokenPipeError as e:
            print(f"âœ— [Errno 32] Broken pipe ë°œìƒ - FFmpeg íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜")
            print(f"   ì›ì¸: MoviePy write_videofile ì¤‘ FFmpegì™€ì˜ í†µì‹  ëŠê¹€")
            print(f"   í•´ê²°: ë¹„ë””ì˜¤ ê¸¸ì´ ë‹¨ì¶•, ë©”ëª¨ë¦¬ í™•ë³´, ë˜ëŠ” ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸")
            raise Exception(f"ë¹„ë””ì˜¤ ì €ì¥ ì¤‘ íŒŒì´í”„ ì˜¤ë¥˜ ë°œìƒ: {e}")
        except Exception as e:
            print(f"âœ— ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì‹¤í–‰)
            try:
                if 'audio_clips' in locals():
                    for audio_clip in audio_clips:
                        if audio_clip:
                            audio_clip.close()
                if 'combined_audio' in locals() and combined_audio:
                    combined_audio.close()
                if 'final_video' in locals() and final_video:
                    final_video.close()
                print("[DEBUG] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            except Exception as cleanup_error:
                print(f"[WARNING] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {cleanup_error}")

    def _create_intro_clip(self, duration: float = 3, hook_phrase: str = None) -> VideoClip:
        """
        ì¸íŠ¸ë¡œ í´ë¦½ ìƒì„± (AI ìë™ ìƒì„± í›… í¬í•¨)

        Args:
            duration: ì¸íŠ¸ë¡œ ì§€ì† ì‹œê°„
            hook_phrase: AIê°€ ìƒì„±í•œ ë°”ì´ëŸ´ í›… ë¬¸êµ¬ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)

        Returns:
            ì¸íŠ¸ë¡œ VideoClip
        """
        # ì¸íŠ¸ë¡œ ì´ë¯¸ì§€ ìš°ì„ ìˆœìœ„: ì»¤ìŠ¤í…€ > Kelly ìºë¦­í„° > ê¸°ë³¸ ë°°ê²½
        intro_image_path = None

        # 1. ì»¤ìŠ¤í…€ ì´ë¯¸ì§€ í™•ì¸
        if self.intro_custom_image and os.path.exists(self.intro_custom_image):
            print(f"âœ“ ì»¤ìŠ¤í…€ ì¸íŠ¸ë¡œ ì´ë¯¸ì§€ ì‚¬ìš©: {self.intro_custom_image}")
            intro_image_path = self.intro_custom_image
        # 2. Kelly ìºë¦­í„° ì´ë¯¸ì§€ ë¡œë“œ (Shortsì—ì„œë„ Kelly ì‚¬ìš©)
        elif self.resource_manager:
            kelly_candidates = [
                os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_casual_hoodie.png"),
                os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_ponytail.png"),
                os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_glasses.png"),
            ]
            for path in kelly_candidates:
                if os.path.exists(path):
                    intro_image_path = path
                    print(f"âœ“ [Shorts ì¸íŠ¸ë¡œ] Kelly ì´ë¯¸ì§€ ë¡œë“œ: {os.path.basename(path)}")
                    break

            if not intro_image_path:
                print("âš  [Shorts ì¸íŠ¸ë¡œ] Kelly ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°°ê²½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # ë°°ê²½ ì„¤ì •
        if intro_image_path and os.path.exists(intro_image_path):
            bg = ImageClip(intro_image_path).with_duration(duration)

            # ë””ë²„ê¹…: ì´ë¯¸ì§€ í¬ê¸° ì¶œë ¥
            print(f"ğŸ“¸ ì¸íŠ¸ë¡œ ì´ë¯¸ì§€ í¬ê¸°: {bg.w}x{bg.h}")

            # ì´ë¯¸ì§€ê°€ ê°€ë¡œ ë°©í–¥ì´ë©´ 90ë„ íšŒì „
            if bg.w > bg.h:
                print(f"âš  ì¸íŠ¸ë¡œ ì´ë¯¸ì§€ê°€ ê°€ë¡œ ë°©í–¥ì…ë‹ˆë‹¤ ({bg.w}x{bg.h}). 90ë„ íšŒì „í•©ë‹ˆë‹¤.")
                bg = bg.rotated(90)
                print(f"âœ“ íšŒì „ í›„ í¬ê¸°: {bg.w}x{bg.h}")
            else:
                print(f"âœ“ ì¸íŠ¸ë¡œ ì´ë¯¸ì§€ê°€ ì´ë¯¸ ì„¸ë¡œ ë°©í–¥ì…ë‹ˆë‹¤")

            bg = bg.resized(height=self.height)
            if bg.w > self.width:
                bg = bg.cropped(x_center=bg.w / 2, width=self.width, height=self.height)
            elif bg.w < self.width:
                bg_fill = ColorClip(size=(self.width, self.height), color=(100, 150, 255)).with_duration(duration)
                bg = CompositeVideoClip([bg_fill, bg.with_position('center')])
        else:
            # í´ë°±: PILë¡œ ê·¸ë¼ë°ì´ì…˜ ìƒì„± (DALL-E ì‹¤íŒ¨ ì‹œ)
            print("âš  DALL-E ì´ë¯¸ì§€ ì—†ìŒ. í´ë°± ê·¸ë¼ë°ì´ì…˜ ìƒì„± ì¤‘...")
            from PIL import Image
            import numpy as np

            # ê·¸ë¼ë°ì´ì…˜ ì´ë¯¸ì§€ ìƒì„±
            gradient = Image.new('RGB', (self.width, self.height))
            pixels = gradient.load()

            # ìƒë‹¨ ìƒ‰ìƒ (ë°ì€ í•˜ëŠ˜ìƒ‰) â†’ í•˜ë‹¨ ìƒ‰ìƒ (ì§„í•œ íŒŒìŠ¤í…” ë¸”ë£¨)
            top_color = (173, 216, 230)      # Light Blue
            bottom_color = (100, 149, 237)   # Cornflower Blue

            # ê·¸ë¼ë°ì´ì…˜ ìƒì„±
            for y in range(self.height):
                # 0.0 (ìƒë‹¨) ~ 1.0 (í•˜ë‹¨)
                ratio = y / self.height

                # ìƒ‰ìƒ ë³´ê°„
                r = int(top_color[0] * (1 - ratio) + bottom_color[0] * ratio)
                g = int(top_color[1] * (1 - ratio) + bottom_color[1] * ratio)
                b = int(top_color[2] * (1 - ratio) + bottom_color[2] * ratio)

                # ê°€ë¡œì¤„ ì „ì²´ì— ìƒ‰ìƒ ì ìš©
                for x in range(self.width):
                    pixels[x, y] = (r, g, b)

            # PIL Imageë¥¼ MoviePy ImageClipìœ¼ë¡œ ë³€í™˜
            gradient_array = np.array(gradient)
            bg = ImageClip(gradient_array).with_duration(duration)
            print("âœ“ í´ë°± ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒì„± ì™„ë£Œ")

        # í…ìŠ¤íŠ¸ (í•œê¸€ ì§€ì› í°íŠ¸ - ì§ì ‘ ê²½ë¡œ ì§€ì •)
        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # ===== Kelly Cat ì¶”ê°€ ì—¬ë¶€ ê²°ì • =====
        layers = [bg]  # ê¸°ë³¸ ë°°ê²½

        if self.use_kelly and self.image_generator:
            # Kelly Cat ì¸íŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
            try:
                kelly_image_path = self.image_generator.generate_kelly_for_scenario('intro')
                kelly_clip = ImageClip(kelly_image_path).with_duration(duration)

                # Kellyë¥¼ í•˜ë‹¨ì— ë°°ì¹˜ (í¬ê¸° ì¡°ì ˆ)
                kelly_height = 400  # Kelly í¬ê¸°
                kelly_clip = kelly_clip.resized(height=kelly_height)
                kelly_y = self.height - kelly_height - 50  # í•˜ë‹¨ì—ì„œ 50px ìœ„
                kelly_clip = kelly_clip.with_position(('center', kelly_y))
                kelly_clip = kelly_clip.with_effects([vfx.FadeIn(0.5), vfx.FadeOut(0.5)])

                layers.append(kelly_clip)
                print("âœ… Kelly Cat ì¸íŠ¸ë¡œì— ì¶”ê°€ë¨")

                # Kelly ëŒ€ì‚¬ ì‚¬ìš©
                intro_text = get_random_intro() if not hook_phrase else hook_phrase
            except Exception as e:
                print(f"âš  Kelly ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}. ê¸°ë³¸ ì¸íŠ¸ë¡œ ì‚¬ìš©")
                intro_text = hook_phrase if hook_phrase else "ì˜¤ëŠ˜ì˜ 3ë¬¸ì¥\nDaily English"
        else:
            # Kelly ì—†ì´ ê¸°ë³¸ ì¸íŠ¸ë¡œ
            intro_text = hook_phrase if hook_phrase else "ì˜¤ëŠ˜ì˜ 3ë¬¸ì¥\nDaily English"

        # ===== í…ìŠ¤íŠ¸ ë°•ìŠ¤ì™€ í›… ë¬¸êµ¬ =====
        # ë°°ê²½ ë°•ìŠ¤ í¬ê¸°: ë„“ê³  ì¶©ë¶„í•œ ë†’ì´ (í…ìŠ¤íŠ¸ê°€ 2-3ì¤„ì¼ ìˆ˜ ìˆìŒ)
        text_bg = ColorClip(
            size=(self.width - 80, 450),  # ë„ˆë¹„: ê±°ì˜ ì „ì²´, ë†’ì´: ë„‰ë„‰í•˜ê²Œ
            color=(0, 0, 0),  # ê²€ì€ìƒ‰
            duration=duration
        ).with_opacity(0.75).with_position(('center', 300))  # Kelly ìœ„ì— ë°°ì¹˜

        # í›… í…ìŠ¤íŠ¸ (ë°°ê²½ ë°•ìŠ¤ ìœ„ì— ë°°ì¹˜)
        txt_hook = TextClip(
            text=intro_text,
            font_size=68,  # í°íŠ¸ í¬ê¸° (Kellyì™€ í•¨ê»˜ ì‚¬ìš© ì‹œ ì•½ê°„ ì‘ê²Œ)
            color='white',
            font=korean_font,
            size=(self.width - 160, None),  # ë°•ìŠ¤ë³´ë‹¤ ì•½ê°„ ì‘ê²Œ
            method='caption',
            text_align='center',
            stroke_color='#FFD700',  # Gold stroke (ë¸Œëœë”© ìƒ‰ìƒ)
            stroke_width=4,
            margin=(20, 30)
        ).with_position(('center', 350)).with_duration(duration)

        # í˜ì´ë“œ íš¨ê³¼
        text_bg = text_bg.with_effects([vfx.FadeIn(0.5), vfx.FadeOut(0.5)])
        txt_hook = txt_hook.with_effects([vfx.FadeIn(0.5), vfx.FadeOut(0.5)])

        # ë ˆì´ì–´ ì¶”ê°€
        layers.extend([text_bg, txt_hook])

        # ë ˆì´ì–´ ìˆœì„œ: ë°°ê²½ â†’ Kelly â†’ ë°˜íˆ¬ëª… ë°•ìŠ¤ â†’ í›… í…ìŠ¤íŠ¸
        return CompositeVideoClip(layers, size=(self.width, self.height))

    def _calculate_font_size(self, text: str) -> int:
        """
        í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ ë™ì ìœ¼ë¡œ í°íŠ¸ í¬ê¸° ê³„ì‚°

        Args:
            text: í‘œì‹œí•  í…ìŠ¤íŠ¸ (ì˜ì–´ + í•œê¸€ ë²ˆì—­ í¬í•¨)

        Returns:
            ì ì ˆí•œ í°íŠ¸ í¬ê¸° (px)
        """
        text_length = len(text)

        # í…ìŠ¤íŠ¸ ê¸¸ì´ë³„ í°íŠ¸ í¬ê¸° (ì§§ì€ ë¬¸ì¥ì€ í¬ê²Œ, ê¸´ ë¬¸ì¥ì€ ì‘ê²Œ)
        if text_length < 50:
            return 58  # ë§¤ìš° ì§§ì€ ë¬¸ì¥ â†’ í¬ê²Œ
        elif text_length < 80:
            return 52  # ì§§ì€ ë¬¸ì¥
        elif text_length < 120:
            return 46  # ë³´í†µ ê¸¸ì´
        elif text_length < 160:
            return 42  # ê¸´ ë¬¸ì¥ (í˜„ì¬ ê¸°ë³¸ê°’)
        else:
            return 38  # ë§¤ìš° ê¸´ ë¬¸ì¥ â†’ ì‘ê²Œ (ì˜¤ë²„í”Œë¡œìš° ë°©ì§€)

    def _create_sentence_clip(
        self,
        image_path: str,
        sentences: list[str],
        translations: list[str],
        duration: float,
        start_time: float = 0,
        tts_duration: float = None,
        format_type: str = "shorts"
    ) -> VideoClip:
        """
        ë¬¸ì¥ í´ë¦½ ìƒì„±

        Args:
            image_path: ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ
            sentences: í‘œì‹œí•  ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
            translations: í•œê¸€ ë²ˆì—­ ë¦¬ìŠ¤íŠ¸
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            start_time: ì˜¤ë””ì˜¤ ì‹œì‘ ì‹œê°„ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, í˜¸í™˜ì„± ìœ ì§€)
            tts_duration: (ì‚¬ìš© ì•ˆ í•¨, í˜¸í™˜ì„± ìœ ì§€)
            format_type: ë¹„ë””ì˜¤ í¬ë§· ("shorts" = 9:16 ì„¸ë¡œ, "longform" = 16:9 ê°€ë¡œ)

        Returns:
            ë¬¸ì¥ VideoClip
        """
        # ë°°ê²½ ì´ë¯¸ì§€ (PILë¡œ ë¨¼ì € íšŒì „ ì²˜ë¦¬)
        from PIL import Image
        import tempfile

        pil_image = Image.open(image_path)
        original_w, original_h = pil_image.size
        print(f"ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {original_w}x{original_h} (ê²½ë¡œ: {image_path.split('/')[-1]})")

        # Shorts í¬ë§·: ì´ë¯¸ì§€ê°€ ê°€ë¡œ ë°©í–¥ì´ë©´ 90ë„ íšŒì „ (ì„¸ë¡œ ì˜ìƒì´ì–´ì•¼ í•¨)
        # Longform í¬ë§·: ì´ë¯¸ì§€ê°€ ì„¸ë¡œ ë°©í–¥ì´ë©´ 90ë„ íšŒì „ (ê°€ë¡œ ì˜ìƒì´ì–´ì•¼ í•¨)
        rotated_image_path = image_path  # ê¸°ë³¸ê°’: íšŒì „ ì•ˆ í•¨

        if format_type == "longform":
            # ë¡±í¼ì€ 16:9 ê°€ë¡œ í¬ë§· â†’ ì„¸ë¡œ ì´ë¯¸ì§€ë¥¼ ê°€ë¡œë¡œ íšŒì „
            if original_h > original_w:
                print(f"âš  [ë¡±í¼] ì´ë¯¸ì§€ê°€ ì„¸ë¡œ ë°©í–¥ì…ë‹ˆë‹¤ ({original_w}x{original_h}). 90ë„ íšŒì „í•©ë‹ˆë‹¤.")
                # transposeë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ 90ë„ íšŒì „ (ë°˜ì‹œê³„ ë°©í–¥)
                pil_image = pil_image.transpose(Image.ROTATE_90)  # 90ë„ ë°˜ì‹œê³„ ë°©í–¥ íšŒì „
                print(f"âœ“ íšŒì „ í›„ í¬ê¸°: {pil_image.size}")

                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:
                    pil_image.save(tmp.name, 'PNG')
                    rotated_image_path = tmp.name
            else:
                print(f"âœ“ [ë¡±í¼] ì´ë¯¸ì§€ê°€ ì´ë¯¸ ê°€ë¡œ ë°©í–¥ì…ë‹ˆë‹¤ ({original_w}x{original_h})")
        else:
            # ShortsëŠ” 9:16 ì„¸ë¡œ í¬ë§· â†’ ê°€ë¡œ ì´ë¯¸ì§€ë¥¼ ì„¸ë¡œë¡œ íšŒì „
            if original_w > original_h:
                print(f"âš  [Shorts] ì´ë¯¸ì§€ê°€ ê°€ë¡œ ë°©í–¥ì…ë‹ˆë‹¤ ({original_w}x{original_h}). 90ë„ íšŒì „í•©ë‹ˆë‹¤.")
                # transposeë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ 90ë„ íšŒì „ (ë°˜ì‹œê³„ ë°©í–¥)
                pil_image = pil_image.transpose(Image.ROTATE_90)  # 90ë„ ë°˜ì‹œê³„ ë°©í–¥ íšŒì „
                print(f"âœ“ íšŒì „ í›„ í¬ê¸°: {pil_image.size}")

                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:
                    pil_image.save(tmp.name, 'PNG')
                    rotated_image_path = tmp.name
            else:
                print(f"âœ“ [Shorts] ì´ë¯¸ì§€ê°€ ì´ë¯¸ ì„¸ë¡œ ë°©í–¥ì…ë‹ˆë‹¤ ({original_w}x{original_h})")

        # MoviePy ImageClip ìƒì„±
        img = ImageClip(rotated_image_path).with_duration(duration)
        print(f"ğŸ“¸ MoviePy í´ë¦½ í¬ê¸°: {img.w}x{img.h}")

        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (í¬ë§·ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬)
        if format_type == "longform":
            # ë¡±í¼: 16:9 ê°€ë¡œ â†’ width ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ
            img = img.resized(width=self.width)
            if img.h > self.height:
                # ë†’ì´ê°€ í¬ë©´ ì¤‘ì•™ í¬ë¡­
                img = img.cropped(
                    y_center=img.h / 2,
                    width=self.width,
                    height=self.height
                )
            elif img.h < self.height:
                # ë†’ì´ê°€ ì‘ìœ¼ë©´ íŒ¨ë”©
                bg = ColorClip(
                    size=(self.width, self.height),
                    color=(255, 255, 255)
                ).with_duration(duration)
                img = CompositeVideoClip([bg, img.with_position('center')])
        else:
            # Shorts: 9:16 ì„¸ë¡œ â†’ height ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ
            img = img.resized(height=self.height)
            if img.w > self.width:
                # ë„ˆë¹„ê°€ í¬ë©´ ì¤‘ì•™ í¬ë¡­
                img = img.cropped(
                    x_center=img.w / 2,
                    width=self.width,
                    height=self.height
                )
            elif img.w < self.width:
                # ë„ˆë¹„ê°€ ì‘ìœ¼ë©´ íŒ¨ë”©
                bg = ColorClip(
                    size=(self.width, self.height),
                    color=(255, 255, 255)
                ).with_duration(duration)
                img = CompositeVideoClip([bg, img.with_position('center')])

        # ë¬¸ì¥ í…ìŠ¤íŠ¸ (ì˜ì–´ + í•œê¸€ ë²ˆì—­)
        text_clips = []

        # í•œê¸€ í°íŠ¸ ê²½ë¡œ
        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ (ê°€ë…ì„± í–¥ìƒ) - í™”ë©´ í•˜ë‹¨ì— ì‘ê²Œ ë°°ì¹˜
        # í¬ë§·ì— ë”°ë¼ ìœ„ì¹˜ ì¡°ì • (Shorts: 1400, Longform: 650)
        txt_bg_y = 650 if format_type == "longform" else 1400
        txt_bg = ColorClip(
            size=(self.width - 80, 350),  # ë†’ì´ ì¤„ì„ (800 â†’ 350)
            color=(0, 0, 0),
            duration=duration
        ).with_opacity(0.7).with_position(('center', txt_bg_y))
        text_clips.append(txt_bg)

        # ìƒë‹¨ íƒ€ì´í‹€ ì¶”ê°€ (ë¸Œëœë”©) - ë°°ê²½ ë°•ìŠ¤ + í…ìŠ¤íŠ¸
        title_bg = ColorClip(
            size=(550, 70),  # íƒ€ì´í‹€ í¬ê¸°ì— ë§ê²Œ
            color=(0, 0, 0),
            duration=duration
        ).with_opacity(0.75).with_position(('center', 50))
        text_clips.append(title_bg)

        # íƒ€ì´í‹€ í…ìŠ¤íŠ¸ (ë” í¬ê³  ëˆˆì— ë„ê²Œ)
        title = TextClip(
            text="Daily English Mecca",
            font_size=38,  # í¬ê¸° ì¦ê°€ (30 â†’ 38)
            color='white',
            font=korean_font,
            stroke_color='#FFD700',  # ê¸ˆìƒ‰ ì™¸ê³½ì„ ìœ¼ë¡œ ë” ëˆˆì— ë„ê²Œ
            stroke_width=2
        ).with_position(('center', 62)).with_duration(duration)
        text_clips.append(title)

        # === ì˜ì–´ + í•œê¸€ í…ìŠ¤íŠ¸ (ê°„ê²°í•˜ê³  ì•ˆì •ì ì¸ ë°©ì‹) ===

        # ì˜ì–´ì™€ í•œê¸€ì„ í•¨ê»˜ í‘œì‹œ
        combined_lines = []
        for i, sentence in enumerate(sentences):
            combined_lines.append(sentence)  # ì˜ì–´ ë¬¸ì¥
            if translations and i < len(translations):
                combined_lines.append(translations[i])  # í•œê¸€ ë²ˆì—­
            if i < len(sentences) - 1:  # ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ì•„ë‹ˆë©´ ë¹ˆ ì¤„ ì¶”ê°€
                combined_lines.append("")

        combined_text = "\n".join(combined_lines)

        # ë™ì  í°íŠ¸ í¬ê¸° ê³„ì‚°
        dynamic_font_size = self._calculate_font_size(combined_text)

        # í…ìŠ¤íŠ¸ í´ë¦½ ìƒì„± (ê°•í™”ëœ ìŠ¤íƒ€ì¼)
        # í¬ë§·ì— ë”°ë¼ ìœ„ì¹˜ ì¡°ì • (Shorts: 1450, Longform: 700)
        txt_y = 700 if format_type == "longform" else 1450
        txt = TextClip(
            text=combined_text,
            font_size=dynamic_font_size,
            color='white',
            font=korean_font,
            size=(self.width - 120, None),
            method='caption',
            text_align='center',
            stroke_color='black',
            stroke_width=4,  # stroke ë‘ê»ê²Œ (3 â†’ 4)
            margin=(10, 20)
        ).with_position(('center', txt_y)).with_duration(duration)

        text_clips.append(txt)

        # ëª¨ë“  ìš”ì†Œ í•©ì„± (ì „ì²´ í™”ë©´ ì˜¤ë²„ë ˆì´ ì œê±°)
        return CompositeVideoClip(
            [img] + text_clips,
            size=(self.width, self.height)
        )

    def _create_longform_sentence_clip(
        self,
        sentence: str,
        translation: str,
        duration: float,
        kelly_image_path: str = None
    ) -> VideoClip:
        """
        ë¡±í¼ ë¹„ë””ì˜¤ìš© ë¬¸ì¥ í´ë¦½ ìƒì„± (Kelly ì™¼ìª½ + ì½˜í…ì¸  ì˜¤ë¥¸ìª½ ë ˆì´ì•„ì›ƒ)

        ë ˆì´ì•„ì›ƒ:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Kelly   â”‚   English Sentence    â”‚
        â”‚  (640px) â”‚   í•œê¸€ ë²ˆì—­            â”‚
        â”‚          â”‚   (1280px)            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        Args:
            sentence: ì˜ì–´ ë¬¸ì¥
            translation: í•œê¸€ ë²ˆì—­
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            kelly_image_path: Kelly ìºë¦­í„° ì´ë¯¸ì§€ ê²½ë¡œ

        Returns:
            ë¬¸ì¥ VideoClip
        """
        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
        layers = []

        # 1. ë°°ê²½ (íŒŒìŠ¤í…” ë¸”ë£¨)
        bg = ColorClip(
            size=(self.width, self.height),
            color=(220, 235, 255),  # ì—°í•œ íŒŒìŠ¤í…” ë¸”ë£¨
            duration=duration
        )
        layers.append(bg)

        # 2. Kelly ì˜ì—­ (ì™¼ìª½ 1/3, ë” ì§„í•œ íŒŒìŠ¤í…”)
        kelly_bg = ColorClip(
            size=(self.kelly_width, self.height),
            color=(200, 220, 255),  # ë” ì§„í•œ íŒŒìŠ¤í…” ë¸”ë£¨
            duration=duration
        ).with_position((0, 0))
        layers.append(kelly_bg)

        # 3. Kelly ìºë¦­í„° ì´ë¯¸ì§€ (ì™¼ìª½ ì˜ì—­ì— ë°°ì¹˜)
        if kelly_image_path and os.path.exists(kelly_image_path):
            kelly_clip = ImageClip(kelly_image_path).with_duration(duration)

            # Kelly ì´ë¯¸ì§€ë¥¼ ì™¼ìª½ ì˜ì—­ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€)
            kelly_clip = kelly_clip.resized(height=self.height * 0.8)  # 80% ë†’ì´

            # Kellyë¥¼ ì™¼ìª½ ì˜ì—­ ì¤‘ì•™ì— ë°°ì¹˜
            kelly_x = (self.kelly_width - kelly_clip.w) // 2
            kelly_y = (self.height - kelly_clip.h) // 2
            kelly_clip = kelly_clip.with_position((kelly_x, kelly_y))

            # í˜ì´ë“œ íš¨ê³¼
            kelly_clip = kelly_clip.with_effects([vfx.FadeIn(0.3), vfx.FadeOut(0.3)])

            layers.append(kelly_clip)
        else:
            print(f"âš ï¸ Kelly ì´ë¯¸ì§€ ì—†ìŒ, ê¸°ë³¸ ë°°ê²½ë§Œ ì‚¬ìš©")

        # 4. êµ¬ë¶„ì„  (Kelly ì˜ì—­ê³¼ ì½˜í…ì¸  ì˜ì—­ ì‚¬ì´)
        divider = ColorClip(
            size=(4, self.height),  # 4px ë‘ê»˜
            color=(100, 150, 200),  # ì§„í•œ ë¸”ë£¨
            duration=duration
        ).with_position((self.kelly_width, 0))
        layers.append(divider)

        # 5. ì˜ì–´ ë¬¸ì¥ (ì˜¤ë¥¸ìª½ ì˜ì—­ ìƒë‹¨)
        sentence_txt = TextClip(
            text=sentence,
            font_size=60,
            color='#2C3E50',  # ì§„í•œ ë„¤ì´ë¹„
            font=korean_font,
            size=(self.content_width - 100, None),  # ì¢Œìš° ì—¬ë°± 50pxì”©
            method='caption',
            text_align='center',
            stroke_color='white',
            stroke_width=3,
            margin=(10, 20)
        ).with_position((self.kelly_width + 50, 300)).with_duration(duration)  # y=300 (ìƒë‹¨)

        layers.append(sentence_txt)

        # 6. í•œê¸€ ë²ˆì—­ (ì˜¤ë¥¸ìª½ ì˜ì—­ í•˜ë‹¨)
        translation_txt = TextClip(
            text=translation,
            font_size=45,
            color='#7F8C8D',  # íšŒìƒ‰
            font=korean_font,
            size=(self.content_width - 100, None),
            method='caption',
            text_align='center',
            stroke_color='white',
            stroke_width=2,
            margin=(10, 20)
        ).with_position((self.kelly_width + 50, 600)).with_duration(duration)  # y=600 (í•˜ë‹¨)

        layers.append(translation_txt)

        # 7. ëª¨ë“  ë ˆì´ì–´ í•©ì„±
        return CompositeVideoClip(layers, size=(self.width, self.height))

    def _create_outro_clip(self, duration: float = 2) -> VideoClip:
        """
        ì•„ì›ƒíŠ¸ë¡œ í´ë¦½ ìƒì„± (êµ¬ë… ìœ ë„)

        Args:
            duration: ì•„ì›ƒíŠ¸ë¡œ ì§€ì† ì‹œê°„

        Returns:
            ì•„ì›ƒíŠ¸ë¡œ VideoClip
        """
        # ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ìš°ì„ ìˆœìœ„: ì»¤ìŠ¤í…€ > Kelly ìºë¦­í„° > ê¸°ë³¸ ë°°ê²½
        outro_image_path = None

        # 1. ì»¤ìŠ¤í…€ ì´ë¯¸ì§€ í™•ì¸
        if self.outro_custom_image and os.path.exists(self.outro_custom_image):
            print(f"âœ“ ì»¤ìŠ¤í…€ ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ì‚¬ìš©: {self.outro_custom_image}")
            outro_image_path = self.outro_custom_image
        # 2. Kelly ìºë¦­í„° ì´ë¯¸ì§€ ë¡œë“œ (Shortsì—ì„œë„ Kelly ì‚¬ìš©)
        elif self.resource_manager:
            kelly_candidates = [
                os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_casual_hoodie.png"),
                os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_ponytail.png"),
                os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_glasses.png"),
            ]
            for path in kelly_candidates:
                if os.path.exists(path):
                    outro_image_path = path
                    print(f"âœ“ [Shorts ì•„ì›ƒíŠ¸ë¡œ] Kelly ì´ë¯¸ì§€ ë¡œë“œ: {os.path.basename(path)}")
                    break

            if not outro_image_path:
                print("âš  [Shorts ì•„ì›ƒíŠ¸ë¡œ] Kelly ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°°ê²½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # ë°°ê²½ ì„¤ì •
        if outro_image_path and os.path.exists(outro_image_path):
            bg = ImageClip(outro_image_path).with_duration(duration)

            # ë””ë²„ê¹…: ì´ë¯¸ì§€ í¬ê¸° ì¶œë ¥
            print(f"ğŸ“¸ ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ í¬ê¸°: {bg.w}x{bg.h}")

            # ì´ë¯¸ì§€ê°€ ê°€ë¡œ ë°©í–¥ì´ë©´ 90ë„ íšŒì „
            if bg.w > bg.h:
                print(f"âš  ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ê°€ ê°€ë¡œ ë°©í–¥ì…ë‹ˆë‹¤ ({bg.w}x{bg.h}). 90ë„ íšŒì „í•©ë‹ˆë‹¤.")
                bg = bg.rotated(90)
                print(f"âœ“ íšŒì „ í›„ í¬ê¸°: {bg.w}x{bg.h}")
            else:
                print(f"âœ“ ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ê°€ ì´ë¯¸ ì„¸ë¡œ ë°©í–¥ì…ë‹ˆë‹¤")

            bg = bg.resized(height=self.height)
            if bg.w > self.width:
                bg = bg.cropped(x_center=bg.w / 2, width=self.width, height=self.height)
            elif bg.w < self.width:
                bg_fill = ColorClip(size=(self.width, self.height), color=(255, 150, 180)).with_duration(duration)
                bg = CompositeVideoClip([bg_fill, bg.with_position('center')])
        else:
            # ê¸°ë³¸ ë°°ê²½ìƒ‰ (íŒŒìŠ¤í…” í•‘í¬)
            bg = ColorClip(
                size=(self.width, self.height),
                color=(255, 150, 180),
                duration=duration
            )

        # í•œê¸€ í°íŠ¸ ì§ì ‘ ê²½ë¡œ ì§€ì •
        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # ===== Kelly Cat ì¶”ê°€ ì—¬ë¶€ ê²°ì • =====
        layers = [bg]  # ê¸°ë³¸ ë°°ê²½

        if self.use_kelly and self.image_generator:
            # Kelly Cat ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
            try:
                kelly_image_path = self.image_generator.generate_kelly_for_scenario('outro')
                kelly_clip = ImageClip(kelly_image_path).with_duration(duration)

                # Kellyë¥¼ í•˜ë‹¨ì— ë°°ì¹˜
                kelly_height = 450
                kelly_clip = kelly_clip.resized(height=kelly_height)
                kelly_y = self.height - kelly_height - 50
                kelly_clip = kelly_clip.with_position(('center', kelly_y))
                kelly_clip = kelly_clip.with_effects([vfx.FadeIn(0.3)])

                layers.append(kelly_clip)
                print("âœ… Kelly Cat ì•„ì›ƒíŠ¸ë¡œì— ì¶”ê°€ë¨")

                # Kelly ëŒ€ì‚¬ ì‚¬ìš©
                outro_message = get_random_outro()
            except Exception as e:
                print(f"âš  Kelly ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}. ê¸°ë³¸ ì•„ì›ƒíŠ¸ë¡œ ì‚¬ìš©")
                outro_message = "ëŒ“ê¸€ì— ì˜¤ëŠ˜ ë°°ìš´ ë¬¸ì¥ ì¨ë³´ì„¸ìš”!"
        else:
            outro_message = "ëŒ“ê¸€ì— ì˜¤ëŠ˜ ë°°ìš´ ë¬¸ì¥ ì¨ë³´ì„¸ìš”!"

        # ===== í…ìŠ¤íŠ¸ ë ˆì´ì–´ =====
        # ë¸Œëœë”© í…ìŠ¤íŠ¸ (ìƒë‹¨)
        branding_text = TextClip(
            text="Daily English Mecca",
            font_size=54,
            color='#FFD700',
            font=korean_font,
            stroke_color='white',
            stroke_width=3,
            text_align='center'
        ).with_position(('center', 300)).with_duration(duration)

        # ë©”ì¸ CTA (ì¤‘ì•™)
        main_txt = TextClip(
            text="ì¢‹ì•„ìš” & êµ¬ë…í•˜ê¸°!",
            font_size=58,
            color='white',
            font=korean_font,
            size=(self.width - 120, None),
            method='caption',
            text_align='center',
            stroke_color='#FFD700',
            stroke_width=4,
            margin=(10, 20)
        ).with_position(('center', 450)).with_duration(duration)

        # Kelly ëŒ€ì‚¬ ë˜ëŠ” ê¸°ë³¸ ë©”ì‹œì§€
        sub_txt = TextClip(
            text=outro_message,
            font_size=40,
            color='white',
            font=korean_font,
            size=(self.width - 100, None),
            method='caption',
            text_align='center',
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)
        ).with_position(('center', 650)).with_duration(duration)

        # í˜ì´ë“œ íš¨ê³¼
        branding_text = branding_text.with_effects([vfx.FadeIn(0.3)])
        main_txt = main_txt.with_effects([vfx.FadeIn(0.3)])
        sub_txt = sub_txt.with_effects([vfx.FadeIn(0.5)])

        # ë ˆì´ì–´ ì¶”ê°€
        layers.extend([branding_text, main_txt, sub_txt])

        # ë ˆì´ì–´ ìˆœì„œ: ë°°ê²½ â†’ Kelly â†’ ë¸Œëœë”© â†’ CTA â†’ ë©”ì‹œì§€
        return CompositeVideoClip(
            layers,
            size=(self.width, self.height)
        )

    def _create_longform_intro_clip(self, duration: float = 5, kelly_image_path: str = None) -> VideoClip:
        """
        ë¡±í¼ ë¹„ë””ì˜¤ìš© ì¸íŠ¸ë¡œ í´ë¦½ ìƒì„±

        Args:
            duration: ì¸íŠ¸ë¡œ ì§€ì† ì‹œê°„
            kelly_image_path: Kelly ì´ë¯¸ì§€ ê²½ë¡œ

        Returns:
            ì¸íŠ¸ë¡œ VideoClip
        """
        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
        layers = []

        # 1. ë°°ê²½ (ê·¸ë¼ë°ì´ì…˜ íš¨ê³¼ë¥¼ ìœ„í•œ íŒŒìŠ¤í…” ë¸”ë£¨)
        bg = ColorClip(
            size=(self.width, self.height),
            color=(180, 210, 255),  # íŒŒìŠ¤í…” ë¸”ë£¨
            duration=duration
        )
        layers.append(bg)

        # 2. Kelly ìºë¦­í„° (ì „ì²´ í™”ë©´ ë°°ê²½)
        if kelly_image_path and os.path.exists(kelly_image_path):
            kelly_clip = ImageClip(kelly_image_path).with_duration(duration)
            # ì „ì²´ í™”ë©´ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (16:9 ë¹„ìœ¨ì— ë§ì¶¤)
            kelly_clip = kelly_clip.resized(height=self.height)
            # ê°€ë¡œê°€ ë¶€ì¡±í•˜ë©´ ê°€ë¡œ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            if kelly_clip.w < self.width:
                kelly_clip = kelly_clip.resized(width=self.width)

            # ì¤‘ì•™ ì •ë ¬
            kelly_clip = kelly_clip.with_position('center')
            kelly_clip = kelly_clip.with_effects([vfx.FadeIn(0.5)])

            # ë°°ê²½ìœ¼ë¡œ ë¨¼ì € ì¶”ê°€ (bg ë‹¤ìŒ, í…ìŠ¤íŠ¸ ì´ì „)
            layers.append(kelly_clip)

        # 3. íƒ€ì´í‹€ (ì¤‘ì•™)
        title_txt = TextClip(
            text="Daily English Mecca",
            font_size=80,
            color='white',
            font=korean_font,
            size=(1200, None),
            method='caption',
            text_align='center',
            stroke_color='#2C3E50',
            stroke_width=6,
            margin=(10, 20)
        ).with_position(('center', 300)).with_duration(duration)

        layers.append(title_txt)

        # 4. ì„œë¸Œíƒ€ì´í‹€ (ì˜¤ëŠ˜ì˜ í•™ìŠµ)
        subtitle_txt = TextClip(
            text="Today's 3 Expressions",
            font_size=50,
            color='#FFD700',  # ê³¨ë“œ
            font=korean_font,
            size=(1000, None),
            method='caption',
            text_align='center',
            stroke_color='black',
            stroke_width=3,
            margin=(10, 20)
        ).with_position(('center', 500)).with_duration(duration)

        layers.append(subtitle_txt)

        # 5. í˜ì´ë“œ íš¨ê³¼
        title_txt = title_txt.with_effects([vfx.FadeIn(0.8)])
        subtitle_txt = subtitle_txt.with_effects([vfx.FadeIn(1.0)])

        # 6. ë°°ê²½ ìŒì•… ì¶”ê°€
        intro_video = CompositeVideoClip(layers, size=(self.width, self.height))

        # ë°°ê²½ ìŒì•… ì°¾ê¸° ë° ì¶”ê°€
        background_music_path = None
        if self.resource_manager:
            bg_music_candidates = [
                os.path.join(str(self.resource_manager.resources_dir), "background_music_original.mp3"),
                os.path.join(str(self.resource_manager.resources_dir), "background_music.mp3"),
            ]
            for path in bg_music_candidates:
                if os.path.exists(path):
                    background_music_path = path
                    break

        if background_music_path:
            try:
                print(f"[ì¸íŠ¸ë¡œ] ë°°ê²½ ìŒì•… ì¶”ê°€: {background_music_path}")
                bg_music = AudioFileClip(background_music_path)
                # ë³¼ë¥¨ 10% (ì¸íŠ¸ë¡œëŠ” ìŒì„± ì—†ì–´ì„œ ì¡°ê¸ˆ ë” í¬ê²Œ)
                bg_music = bg_music * 0.10
                # ì¸íŠ¸ë¡œ ê¸¸ì´ë§Œí¼ ìë¥´ê¸°
                if bg_music.duration >= duration:
                    bg_music = bg_music.subclipped(0, duration)
                bg_music = bg_music.with_start(0)

                # ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ì¶”ê°€
                intro_video = intro_video.with_audio(bg_music)
                print(f"  - ë°°ê²½ ìŒì•… {duration:.2f}ì´ˆ ì¶”ê°€ ì™„ë£Œ (ë³¼ë¥¨ 10%)")
            except Exception as e:
                print(f"âš  ë°°ê²½ ìŒì•… ì¶”ê°€ ì‹¤íŒ¨: {e}")

        return intro_video

    def _create_longform_outro_clip(self, duration: float = 5, kelly_image_path: str = None) -> VideoClip:
        """
        ë¡±í¼ ë¹„ë””ì˜¤ìš© ì•„ì›ƒíŠ¸ë¡œ í´ë¦½ ìƒì„±

        Args:
            duration: ì•„ì›ƒíŠ¸ë¡œ ì§€ì† ì‹œê°„
            kelly_image_path: Kelly ì´ë¯¸ì§€ ê²½ë¡œ

        Returns:
            ì•„ì›ƒíŠ¸ë¡œ VideoClip
        """
        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
        layers = []

        # 1. ë°°ê²½ (íŒŒìŠ¤í…” í•‘í¬)
        bg = ColorClip(
            size=(self.width, self.height),
            color=(255, 200, 220),  # íŒŒìŠ¤í…” í•‘í¬
            duration=duration
        )
        layers.append(bg)

        # 2. Kelly ìºë¦­í„° (ì „ì²´ í™”ë©´ ë°°ê²½)
        if kelly_image_path and os.path.exists(kelly_image_path):
            kelly_clip = ImageClip(kelly_image_path).with_duration(duration)
            # ì „ì²´ í™”ë©´ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (16:9 ë¹„ìœ¨ì— ë§ì¶¤)
            kelly_clip = kelly_clip.resized(height=self.height)
            # ê°€ë¡œê°€ ë¶€ì¡±í•˜ë©´ ê°€ë¡œ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            if kelly_clip.w < self.width:
                kelly_clip = kelly_clip.resized(width=self.width)

            # ì¤‘ì•™ ì •ë ¬
            kelly_clip = kelly_clip.with_position('center')
            kelly_clip = kelly_clip.with_effects([vfx.FadeIn(0.3)])

            # ë°°ê²½ìœ¼ë¡œ ë¨¼ì € ì¶”ê°€ (bg ë‹¤ìŒ, í…ìŠ¤íŠ¸ ì´ì „)
            layers.append(kelly_clip)

        # 3. ë©”ì¸ CTA (ì¤‘ì•™)
        main_txt = TextClip(
            text="ì¢‹ì•„ìš” & êµ¬ë… & ì•Œë¦¼ì„¤ì •!",
            font_size=70,
            color='white',
            font=korean_font,
            size=(1200, None),
            method='caption',
            text_align='center',
            stroke_color='#E74C3C',  # ë¹¨ê°„ìƒ‰
            stroke_width=5,
            margin=(10, 20)
        ).with_position(('center', 300)).with_duration(duration)

        layers.append(main_txt)

        # 4. ì„œë¸Œ ë©”ì‹œì§€ (ì¤‘ì•™)
        sub_txt = TextClip(
            text="ëŒ“ê¸€ì— ì˜¤ëŠ˜ ë°°ìš´ í‘œí˜„ ì¨ë³´ì„¸ìš”!",
            font_size=45,
            color='#FFD700',  # ê³¨ë“œ
            font=korean_font,
            size=(1000, None),
            method='caption',
            text_align='center',
            stroke_color='black',
            stroke_width=3,
            margin=(10, 20)
        ).with_position(('center', 500)).with_duration(duration)

        layers.append(sub_txt)

        # 5. í˜ì´ë“œ íš¨ê³¼
        main_txt = main_txt.with_effects([vfx.FadeIn(0.5)])
        sub_txt = sub_txt.with_effects([vfx.FadeIn(0.8)])

        return CompositeVideoClip(layers, size=(self.width, self.height))

    def create_quiz_video(
        self,
        quiz_data: dict,
        audio_info: list[dict],
        output_path: str
    ) -> str:
        """
        í€´ì¦ˆ ì±Œë¦°ì§€ ì „ìš© ë¹„ë””ì˜¤ ìƒì„±

        Args:
            quiz_data: í€´ì¦ˆ ë°ì´í„°
                {
                    'question': 'ë¬¸ì œ ì§ˆë¬¸',
                    'option_a': 'ì„ íƒì§€ A',
                    'option_b': 'ì„ íƒì§€ B',
                    'correct_answer': 'A' or 'B',
                    'explanation': 'í•´ì„¤',
                    'examples': ['ì˜ˆë¬¸1', 'ì˜ˆë¬¸2', 'ì˜ˆë¬¸3']
                }
            audio_info: ê° í•­ëª©ë³„ ì˜¤ë””ì˜¤ ì •ë³´ (8ê°œ)
            output_path: ë¹„ë””ì˜¤ ì €ì¥ ê²½ë¡œ

        Returns:
            ìƒì„±ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        try:
            print("í€´ì¦ˆ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")

            # === 1. ì¸íŠ¸ë¡œ (3ì´ˆ): Daily English Mecca ===
            intro_clip = self._create_intro_clip(duration=3, hook_phrase="í•œêµ­ì¸ 95% í‹€ë¦¬ëŠ” ë¬¸ì œ!")

            # ì‹¤ì œ TTS ê¸¸ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¦½ duration ê³„ì‚°
            # ê° ì¥ë©´ ì‚¬ì´ì— 2ì´ˆ ê°„ê²© ì¶”ê°€ (ì‚¬ìš©ì ìƒê° ì‹œê°„)
            pause_between_scenes = 2.0  # ì¥ë©´ ì „í™˜ ê°„ê²© (ì¼ë°˜ ì¥ë©´ìš©)

            # ì§ˆë¬¸ (í•œê¸€) + ì„ íƒì§€ (ì˜ì–´) = ì²« 2ê°œ TTS
            question_tts_duration = audio_info[0]['voices']['alloy']['duration'] + audio_info[1]['voices']['alloy']['duration']
            question_duration = question_tts_duration  # TTSë§Œ (pause ì œê±°, ì¹´ìš´íŠ¸ë‹¤ìš´ í´ë¦½ì´ ëŒ€ì‹  í•¨)

            # === 2. ë¬¸ì œ ì œì‹œ (ì‹¤ì œ TTS ê¸¸ì´ë§Œ, pause ì—†ìŒ) ===
            question_clip_obj = QuestionClip()
            question_clip = question_clip_obj.create(
                question=quiz_data['question'],
                option_a=quiz_data['option_a'],
                option_b=quiz_data['option_b'],
                duration=question_duration
            )

            # === 2-1. ì¹´ìš´íŠ¸ë‹¤ìš´ í´ë¦½ (3ì´ˆ ëŒ€ê¸°, 3-2-1 ì• ë‹ˆë©”ì´ì…˜) ===
            countdown_clip_obj = CountdownClip()
            countdown_clip = countdown_clip_obj.create(
                question=quiz_data['question'],
                option_a=quiz_data['option_a'],
                option_b=quiz_data['option_b'],
                duration=3.0  # ê³ ì • 3ì´ˆ
            )

            # === 3. ì •ë‹µ ê³µê°œ (ì‹¤ì œ TTS ê¸¸ì´ + ê°„ê²©) ===
            answer_tts_duration = audio_info[2]['voices']['alloy']['duration']
            answer_duration = answer_tts_duration + pause_between_scenes
            answer_clip_obj = AnswerClip()
            answer_clip = answer_clip_obj.create(
                answer=quiz_data['correct_answer'],
                correct_option=quiz_data['option_a'] if quiz_data['correct_answer'] == 'A' else quiz_data['option_b'],
                duration=answer_duration
            )

            # === 4. í•´ì„¤ (ì‹¤ì œ TTS ê¸¸ì´ + ê°„ê²©) ===
            explanation_tts_duration = audio_info[3]['voices']['alloy']['duration']
            explanation_duration = explanation_tts_duration + pause_between_scenes
            explanation_clip_obj = ExplanationClip()
            explanation_clip = explanation_clip_obj.create(
                explanation=quiz_data['explanation'],
                duration=explanation_duration
            )

            # === 5. ì˜ˆë¬¸ë“¤ (ì‹¤ì œ TTS ê¸¸ì´ + ê°„ê²©) ===
            example_clips = []
            for i, example in enumerate(quiz_data['examples']):
                example_tts_duration = audio_info[4 + i]['voices']['alloy']['duration']  # ì˜ˆë¬¸ì€ index 4ë¶€í„°
                example_duration = example_tts_duration + pause_between_scenes
                example_clip_obj = ExampleClip()
                example_clip = example_clip_obj.create(
                    example=example,
                    index=i + 1,
                    duration=example_duration
                )
                example_clips.append(example_clip)

            # === 6. ì•„ì›ƒíŠ¸ë¡œ (3ì´ˆ): CTA ===
            outro_clip = self._create_quiz_outro_clip(duration=3)

            # === ëª¨ë“  í´ë¦½ ì—°ê²° ===
            # ìˆœì„œ: ì¸íŠ¸ë¡œ â†’ ë¬¸ì œ â†’ ì¹´ìš´íŠ¸ë‹¤ìš´(3-2-1) â†’ ì •ë‹µ â†’ í•´ì„¤ â†’ ì˜ˆë¬¸ë“¤ â†’ ì•„ì›ƒíŠ¸ë¡œ
            all_clips = [intro_clip, question_clip, countdown_clip, answer_clip, explanation_clip] + example_clips + [outro_clip]
            final_video = concatenate_videoclips(all_clips, method="compose")

            # === ì˜¤ë””ì˜¤ ì¶”ê°€ (TTS ìŒì„±) ===
            audio_clips = []
            current_time = 3.0  # ì¸íŠ¸ë¡œ 3ì´ˆ í›„ë¶€í„° ì‹œì‘

            # ì‹¤ì œ TTS ê¸¸ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ íƒ€ì´ë° ê³„ì‚°
            for i in range(7):  # ì§ˆë¬¸, ì„ íƒì§€, ì •ë‹µ, í•´ì„¤, ì˜ˆë¬¸3ê°œ (ì´ 7ê°œ, ì¸íŠ¸ë¡œ/ì•„ì›ƒíŠ¸ë¡œ ì œì™¸)
                if i >= len(audio_info):
                    break

                # ì²« ë²ˆì§¸ ìŒì„± ì‚¬ìš© (alloy)
                audio_path = audio_info[i]['voices']['alloy']['path']
                actual_duration = audio_info[i]['voices']['alloy']['duration']

                audio_clip = AudioFileClip(audio_path).with_start(current_time)
                audio_clips.append(audio_clip)

                print(f"  TTS {i+1}: {actual_duration:.2f}ì´ˆ (ì‹œì‘: {current_time:.2f}ì´ˆ)")

                # íƒ€ì´ë° ê³„ì‚°
                if i == 1:
                    # ì„ íƒì§€ TTS í›„: ì¹´ìš´íŠ¸ë‹¤ìš´ 3ì´ˆ ëŒ€ê¸°
                    current_time += actual_duration + 3.0
                    print(f"  â†’ ì¹´ìš´íŠ¸ë‹¤ìš´ 3ì´ˆ ëŒ€ê¸° (ë‹¤ìŒ ì‹œì‘: {current_time:.2f}ì´ˆ)")
                else:
                    # ë‚˜ë¨¸ì§€: TTS + pause
                    current_time += actual_duration + pause_between_scenes

            # ì˜¤ë””ì˜¤ í•©ì„±
            from moviepy import CompositeAudioClip
            combined_audio = CompositeAudioClip(audio_clips)

            # ë°°ê²½ ìŒì•… ì¶”ê°€ (ì¸íŠ¸ë¡œ 3ì´ˆì—ë§Œ)
            background_music_path = None
            if self.resource_manager:
                bg_music_candidates = [
                    os.path.join(str(self.resource_manager.resources_dir), "background_music_original.mp3"),
                    os.path.join(str(self.resource_manager.resources_dir), "background_music.mp3"),
                ]
                for path in bg_music_candidates:
                    if os.path.exists(path):
                        background_music_path = path
                        break

            if background_music_path:
                try:
                    print(f"ë°°ê²½ ìŒì•… ì¶”ê°€: {background_music_path}")
                    bg_music = AudioFileClip(background_music_path)
                    bg_music = bg_music * 0.05  # ë³¼ë¥¨ 5%
                    bg_music = bg_music.subclipped(0, 3.0)  # ì¸íŠ¸ë¡œ 3ì´ˆë§Œ
                    bg_music = bg_music.with_start(0)
                    combined_audio = CompositeAudioClip([combined_audio, bg_music])
                except Exception as e:
                    print(f"âš  ë°°ê²½ ìŒì•… ì¶”ê°€ ì‹¤íŒ¨: {e}")

            # ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ì¶”ê°€
            final_video = final_video.with_audio(combined_audio)

            # ë¹„ë””ì˜¤ ì €ì¥
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            print(f"[DEBUG] write_videofile ì‹œì‘ (create_quiz_video): {output_path}")

            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                logger='bar',  # í”„ë¡œê·¸ë ˆìŠ¤ ë°” í‘œì‹œ
                threads=4,     # ë©€í‹°ìŠ¤ë ˆë“œ (ì•ˆì •ì„± í–¥ìƒ)
                ffmpeg_params=['-max_muxing_queue_size', '9999'],  # íŒŒì´í”„ ë²„í¼ ì¦ê°€ (Broken pipe ë°©ì§€)
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True,
                preset='medium'
            )

            print(f"[DEBUG] write_videofile ì™„ë£Œ")

            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            for audio_clip in audio_clips:
                audio_clip.close()
            combined_audio.close()
            final_video.close()

            print(f"âœ“ í€´ì¦ˆ ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
            return output_path

        except BrokenPipeError as e:
            print(f"âœ— [Errno 32] Broken pipe ë°œìƒ - FFmpeg íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜")
            print(f"   ì›ì¸: MoviePy write_videofile ì¤‘ FFmpegì™€ì˜ í†µì‹  ëŠê¹€")
            print(f"   í•´ê²°: ë¹„ë””ì˜¤ ê¸¸ì´ ë‹¨ì¶•, ë©”ëª¨ë¦¬ í™•ë³´, ë˜ëŠ” ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸")
            raise Exception(f"í€´ì¦ˆ ë¹„ë””ì˜¤ ì €ì¥ ì¤‘ íŒŒì´í”„ ì˜¤ë¥˜ ë°œìƒ: {e}")
        except Exception as e:
            print(f"âœ— í€´ì¦ˆ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì‹¤í–‰)
            try:
                if 'audio_clips' in locals():
                    for audio_clip in audio_clips:
                        if audio_clip:
                            audio_clip.close()
                if 'combined_audio' in locals() and combined_audio:
                    combined_audio.close()
                if 'final_video' in locals() and final_video:
                    final_video.close()
                print("[DEBUG] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ (í€´ì¦ˆ)")
            except Exception as cleanup_error:
                print(f"[WARNING] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (í€´ì¦ˆ): {cleanup_error}")

    def _create_quiz_question_clip(self, question: str, option_a: str, option_b: str, duration: float) -> VideoClip:
        """ë¬¸ì œ ì œì‹œ í´ë¦½ (TTS ì¬ìƒë§Œ, pause ì œì™¸)"""
        # íŒŒìŠ¤í…” ë¸”ë£¨ ë°°ê²½
        bg = ColorClip(size=(self.width, self.height), color=(100, 150, 255), duration=duration)

        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # ì§ˆë¬¸
        question_txt = TextClip(
            text=question,
            font_size=48,
            color='white',
            font=korean_font,
            size=(self.width - 120, None),
            method='caption',
            text_align='center',
            stroke_color='black',
            stroke_width=3,
            margin=(10, 20)
        ).with_position(('center', 550)).with_duration(duration)

        # ì„ íƒì§€ A
        option_a_txt = TextClip(
            text=f"A) {option_a}",
            font_size=42,
            color='white',
            font=korean_font,
            size=(self.width - 160, None),
            method='caption',
            text_align='left',
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)
        ).with_position((80, 850)).with_duration(duration)

        # ì„ íƒì§€ B
        option_b_txt = TextClip(
            text=f"B) {option_b}",
            font_size=42,
            color='white',
            font=korean_font,
            size=(self.width - 160, None),
            method='caption',
            text_align='left',
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)
        ).with_position((80, 1050)).with_duration(duration)

        return CompositeVideoClip([bg, question_txt, option_a_txt, option_b_txt], size=(self.width, self.height))

    def _create_quiz_countdown_clip(self, question: str, option_a: str, option_b: str, duration: float = 3.0) -> VideoClip:
        """í€´ì¦ˆ ë¬¸ì œ ì¹´ìš´íŠ¸ë‹¤ìš´ í´ë¦½ (3-2-1 ì• ë‹ˆë©”ì´ì…˜)"""
        # íŒŒìŠ¤í…” ë¸”ë£¨ ë°°ê²½ (ë¬¸ì œ í´ë¦½ê³¼ ë™ì¼)
        bg = ColorClip(size=(self.width, self.height), color=(100, 150, 255), duration=duration)

        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # ì§ˆë¬¸ (ì‘ê²Œ í‘œì‹œ - ìƒë‹¨)
        question_txt = TextClip(
            text=question,
            font_size=36,
            color='white',
            font=korean_font,
            size=(self.width - 120, None),
            method='caption',
            text_align='center',
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)
        ).with_position(('center', 300)).with_duration(duration)  # 400 â†’ 300 (ìœ„ë¡œ ì´ë™)

        # ì„ íƒì§€ A (ì‘ê²Œ)
        option_a_txt = TextClip(
            text=f"A) {option_a}",
            font_size=32,
            color='white',
            font=korean_font,
            size=(self.width - 160, None),
            method='caption',
            text_align='left',
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)
        ).with_position((80, 550)).with_duration(duration)  # 700 â†’ 550 (ìœ„ë¡œ ì´ë™)

        # ì„ íƒì§€ B (ì‘ê²Œ)
        option_b_txt = TextClip(
            text=f"B) {option_b}",
            font_size=32,
            color='white',
            font=korean_font,
            size=(self.width - 160, None),
            method='caption',
            text_align='left',
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)
        ).with_position((80, 680)).with_duration(duration)  # 850 â†’ 680 (ìœ„ë¡œ ì´ë™)

        # ì¹´ìš´íŠ¸ë‹¤ìš´ ìˆ«ìë“¤ (ê° 1ì´ˆì”© í‘œì‹œ)
        countdown_clips = []

        # 3 (0~1ì´ˆ)
        countdown_3 = TextClip(
            text="3",
            font_size=200,
            color='#FFD700',
            font=korean_font,
            stroke_color='black',
            stroke_width=8,
            margin=(20, 30)
        ).with_position(('center', 1100)).with_duration(1.0).with_effects([vfx.FadeIn(0.1), vfx.FadeOut(0.2)])
        countdown_clips.append(countdown_3)

        # 2 (1~2ì´ˆ)
        countdown_2 = TextClip(
            text="2",
            font_size=200,
            color='#FFD700',
            font=korean_font,
            stroke_color='black',
            stroke_width=8,
            margin=(20, 30)
        ).with_position(('center', 1100)).with_start(1.0).with_duration(1.0).with_effects([vfx.FadeIn(0.1), vfx.FadeOut(0.2)])
        countdown_clips.append(countdown_2)

        # 1 (2~3ì´ˆ)
        countdown_1 = TextClip(
            text="1",
            font_size=200,
            color='#FFD700',
            font=korean_font,
            stroke_color='black',
            stroke_width=8,
            margin=(20, 30)
        ).with_position(('center', 1100)).with_start(2.0).with_duration(1.0).with_effects([vfx.FadeIn(0.1), vfx.FadeOut(0.2)])
        countdown_clips.append(countdown_1)

        return CompositeVideoClip([bg, question_txt, option_a_txt, option_b_txt] + countdown_clips, size=(self.width, self.height))

    def _create_quiz_answer_clip(self, correct_answer: str, correct_option: str, duration: float) -> VideoClip:
        """ì •ë‹µ ê³µê°œ í´ë¦½"""
        # íŒŒìŠ¤í…” ê·¸ë¦° ë°°ê²½
        bg = ColorClip(size=(self.width, self.height), color=(100, 200, 100), duration=duration)

        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # "ì •ë‹µì€..." (ì‘ê²Œ)
        title_txt = TextClip(
            text="ì •ë‹µì€...",
            font_size=45,
            color='white',
            font=korean_font,
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)  # ì—¬ë°± ì¶”ê°€ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€
        ).with_position(('center', 550)).with_duration(duration)  # ìœ„ë¡œ ì¡°ì • (600 â†’ 550)

        # ì •ë‹µ (í¬ê²Œ)
        answer_txt = TextClip(
            text=f"{correct_answer}!",
            font_size=120,
            color='#FFD700',
            font=korean_font,
            stroke_color='black',
            stroke_width=5,
            margin=(20, 30)  # ì—¬ë°± ì¶”ê°€ë¡œ í° í…ìŠ¤íŠ¸ ê¹¨ì§ ë°©ì§€
        ).with_position(('center', 750)).with_duration(duration)

        # ì •ë‹µ ë¬¸ì¥
        option_txt = TextClip(
            text=correct_option,
            font_size=40,
            color='white',
            font=korean_font,
            size=(self.width - 120, None),
            method='caption',
            text_align='center',
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)  # ì—¬ë°± ì¶”ê°€ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€
        ).with_position(('center', 950)).with_duration(duration)  # ìœ„ë¡œ ì¡°ì • (1000 â†’ 950)

        # í˜ì´ë“œ íš¨ê³¼
        answer_txt = answer_txt.with_effects([vfx.FadeIn(0.5)])

        return CompositeVideoClip([bg, title_txt, answer_txt, option_txt], size=(self.width, self.height))

    def _create_quiz_explanation_clip(self, explanation: str, duration: float) -> VideoClip:
        """í•´ì„¤ í´ë¦½"""
        # íŒŒìŠ¤í…” ì˜ë¡œìš° ë°°ê²½
        bg = ColorClip(size=(self.width, self.height), color=(255, 220, 100), duration=duration)

        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # "í•´ì„¤" íƒ€ì´í‹€
        title_txt = TextClip(
            text="ğŸ“š í•´ì„¤",
            font_size=45,
            color='white',
            font=korean_font,
            stroke_color='black',
            stroke_width=3,
            margin=(10, 20)  # ì—¬ë°± ì¶”ê°€ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€
        ).with_position(('center', 450)).with_duration(duration)  # ìœ„ë¡œ ì¡°ì • (500 â†’ 450)

        # í•´ì„¤ ë‚´ìš©
        explanation_txt = TextClip(
            text=explanation,
            font_size=38,
            color='black',
            font=korean_font,
            size=(self.width - 120, None),
            method='caption',
            text_align='center',
            margin=(10, 20)  # ì—¬ë°± ì¶”ê°€ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€
        ).with_position(('center', 750)).with_duration(duration)  # ìœ„ë¡œ ì¡°ì • (800 â†’ 750)

        return CompositeVideoClip([bg, title_txt, explanation_txt], size=(self.width, self.height))

    def _create_quiz_example_clip(self, example: str, index: int, duration: float) -> VideoClip:
        """ì˜ˆë¬¸ í´ë¦½"""
        # íŒŒìŠ¤í…” í¼í”Œ ë°°ê²½
        bg = ColorClip(size=(self.width, self.height), color=(180, 150, 255), duration=duration)

        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # "ì˜ˆë¬¸ N" íƒ€ì´í‹€
        title_txt = TextClip(
            text=f"ì˜ˆë¬¸ {index}",
            font_size=40,
            color='white',
            font=korean_font,
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)  # ì—¬ë°± ì¶”ê°€ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€
        ).with_position(('center', 450)).with_duration(duration)  # ìœ„ë¡œ ì¡°ì • (550 â†’ 450)

        # "ì˜ˆë¬¸ì„ ë§í•´ë³¼ê²Œìš”!" ì•ˆë‚´ í…ìŠ¤íŠ¸
        guide_txt = TextClip(
            text="ì˜ˆë¬¸ì„ ë§í•´ë³¼ê²Œìš”!",
            font_size=32,
            color='#FFD700',
            font=korean_font,
            stroke_color='black',
            stroke_width=2,
            margin=(10, 20)
        ).with_position(('center', 600)).with_duration(duration)

        # ì˜ˆë¬¸ ë‚´ìš©
        example_txt = TextClip(
            text=example,
            font_size=48,
            color='white',
            font=korean_font,
            size=(self.width - 120, None),
            method='caption',
            text_align='center',
            stroke_color='black',
            stroke_width=3,
            margin=(10, 20)  # ì—¬ë°± ì¶”ê°€ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€
        ).with_position(('center', 900)).with_duration(duration)  # ì•„ë˜ë¡œ ì¡°ì • (850 â†’ 900)

        return CompositeVideoClip([bg, title_txt, guide_txt, example_txt], size=(self.width, self.height))

    def _create_quiz_outro_clip(self, duration: float) -> VideoClip:
        """í€´ì¦ˆ ì•„ì›ƒíŠ¸ë¡œ (CTA)"""
        # ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ìš°ì„ ìˆœìœ„: ì»¤ìŠ¤í…€ > ìºì‹œ > ìƒì„± > ê¸°ë³¸ ë°°ê²½
        outro_image_path = None

        # 1. ì»¤ìŠ¤í…€ ì´ë¯¸ì§€ í™•ì¸
        if self.outro_custom_image and os.path.exists(self.outro_custom_image):
            print(f"âœ“ ì»¤ìŠ¤í…€ ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ì‚¬ìš©: {self.outro_custom_image}")
            outro_image_path = self.outro_custom_image
        # 2. ìºì‹œëœ í…œí”Œë¦¿ ì´ë¯¸ì§€ í™•ì¸
        elif self.image_generator and self.resource_manager:
            outro_prompt = """A simple geometric abstract background with warm pink coral gradient.
Modern minimalist design with soft shapes and clean composition.
Vertical 9:16 format. Friendly and inviting mood.
Simple flat design with pastel colors."""

            # ìºì‹œ í™•ì¸
            cached_outro = self.resource_manager.get_image_path("outro_template")
            if self.resource_manager.image_exists("outro_template"):
                print("âœ“ ìºì‹œëœ ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ì‚¬ìš©")
                outro_image_path = cached_outro
            else:
                try:
                    print("ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
                    outro_image_path = self.image_generator.generate_image(
                        outro_prompt,
                        cached_outro,
                        size="1024x1792"
                    )
                except Exception as e:
                    print(f"âš  ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ (ê¸°ë³¸ ë°°ê²½ ì‚¬ìš©): {e}")
                    outro_image_path = None

        # ë°°ê²½ ì„¤ì •
        if outro_image_path and os.path.exists(outro_image_path):
            bg = ImageClip(outro_image_path).with_duration(duration)

            # ë””ë²„ê¹…: ì´ë¯¸ì§€ í¬ê¸° ì¶œë ¥
            print(f"ğŸ“¸ ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ í¬ê¸°: {bg.w}x{bg.h}")

            # ì´ë¯¸ì§€ê°€ ê°€ë¡œ ë°©í–¥ì´ë©´ 90ë„ íšŒì „
            if bg.w > bg.h:
                print(f"âš  ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ê°€ ê°€ë¡œ ë°©í–¥ì…ë‹ˆë‹¤ ({bg.w}x{bg.h}). 90ë„ íšŒì „í•©ë‹ˆë‹¤.")
                bg = bg.rotated(90)
                print(f"âœ“ íšŒì „ í›„ í¬ê¸°: {bg.w}x{bg.h}")
            else:
                print(f"âœ“ ì•„ì›ƒíŠ¸ë¡œ ì´ë¯¸ì§€ê°€ ì´ë¯¸ ì„¸ë¡œ ë°©í–¥ì…ë‹ˆë‹¤")

            bg = bg.resized(height=self.height)
            if bg.w > self.width:
                bg = bg.cropped(x_center=bg.w / 2, width=self.width, height=self.height)
            elif bg.w < self.width:
                bg_fill = ColorClip(size=(self.width, self.height), color=(255, 150, 180)).with_duration(duration)
                bg = CompositeVideoClip([bg_fill, bg.with_position('center')])
        else:
            # ê¸°ë³¸ ë°°ê²½ìƒ‰ (íŒŒìŠ¤í…” í•‘í¬)
            bg = ColorClip(
                size=(self.width, self.height),
                color=(255, 150, 180),
                duration=duration
            )

        korean_font = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"

        # ===== ê°œì„ : "Daily English Mecca" ë¸Œëœë”© ì¶”ê°€ (ìµœìƒë‹¨) =====
        branding_text = TextClip(
            text="Daily English Mecca",
            font_size=52,  # í° í°íŠ¸
            color='#FFD700',  # Gold ìƒ‰ìƒ (ë©”ì¸ ë¸Œëœë”©)
            font=korean_font,
            stroke_color='white',  # í°ìƒ‰ ì™¸ê³½ì„ 
            stroke_width=3,
            text_align='center'
        ).with_position(('center', 550)).with_duration(duration)  # ìµœìƒë‹¨ì— ë°°ì¹˜

        # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ ì¶”ê°€ (ê°€ë…ì„± í–¥ìƒ)
        text_bg = ColorClip(
            size=(self.width - 100, 550),  # ë†’ì´ ì¦ê°€ (500 â†’ 550)
            color=(0, 0, 0),
            duration=duration
        ).with_opacity(0.7).with_position(('center', 650))  # ì•„ë˜ë¡œ ì´ë™

        # "ëŒ“ê¸€ì— A or B ë‚¨ê²¨ì£¼ì„¸ìš”!" - í¬ê¸° ì¦ê°€
        main_txt = TextClip(
            text="ëŒ“ê¸€ì— A or B\në‚¨ê²¨ì£¼ì„¸ìš”!",
            font_size=68,  # 52 â†’ 68 (í¬ê¸° ì¦ê°€)
            color='white',
            font=korean_font,
            size=(self.width - 140, None),
            method='caption',
            text_align='center',
            stroke_color='#FFD700',  # Gold stroke (ê°•ì¡°)
            stroke_width=4,
            margin=(10, 20)
        ).with_position(('center', 730)).with_duration(duration)

        # "ì¢‹ì•„ìš” & êµ¬ë…" - í¬ê¸° ì¦ê°€
        sub_txt = TextClip(
            text="ì¢‹ì•„ìš” & êµ¬ë…",
            font_size=56,  # 42 â†’ 56 (í¬ê¸° ì¦ê°€)
            color='#FFD700',
            font=korean_font,
            stroke_color='white',  # í°ìƒ‰ ì™¸ê³½ì„  (ë°˜ì „)
            stroke_width=3,
            margin=(10, 20)
        ).with_position(('center', 970)).with_duration(duration)

        # í˜ì´ë“œ íš¨ê³¼
        branding_text = branding_text.with_effects([vfx.FadeIn(0.3)])
        main_txt = main_txt.with_effects([vfx.FadeIn(0.3)])
        sub_txt = sub_txt.with_effects([vfx.FadeIn(0.5)])

        # ë ˆì´ì–´ ìˆœì„œ: ë°°ê²½ â†’ ë¸Œëœë”© í…ìŠ¤íŠ¸ â†’ ë°˜íˆ¬ëª… ë°•ìŠ¤ â†’ ë©”ì¸ CTA â†’ ì„œë¸Œ CTA
        return CompositeVideoClip([bg, branding_text, text_bg, main_txt, sub_txt], size=(self.width, self.height))

    def create_simple_video(
        self,
        sentences: list[str],
        image_paths: list[str],
        audio_path: str,
        output_path: str
    ) -> str:
        """
        ê°„ë‹¨í•œ ë²„ì „ì˜ ë¹„ë””ì˜¤ ìƒì„± (ì´ë¯¸ì§€ ê°œìˆ˜ì™€ ë¬¸ì¥ ê°œìˆ˜ê°€ ê°™ì„ ë•Œ)

        Args:
            sentences: ì˜ì–´ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
            image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            audio_path: ìŒì„± íŒŒì¼ ê²½ë¡œ
            output_path: ë¹„ë””ì˜¤ ì €ì¥ ê²½ë¡œ

        Returns:
            ìƒì„±ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        # ê° ë¬¸ì¥ì— ì´ë¯¸ì§€ 1ê°œì”© ë§¤í•‘
        image_groups = [[i] for i in range(len(sentences))]
        return self.create_video(
            sentences,
            image_paths,
            audio_path,
            output_path,
            image_groups
        )

    def generate_quiz_preview(
        self,
        quiz_data: dict,
        audio_info: list[dict],
        output_dir: str
    ) -> dict:
        """
        í€´ì¦ˆ ë¹„ë””ì˜¤ í”„ë¦¬ë·° ìƒì„± (ê° í´ë¦½ì˜ ì •ì  ì´ë¯¸ì§€ + íƒ€ì´ë° ì •ë³´)

        Args:
            quiz_data: í€´ì¦ˆ ë°ì´í„°
            audio_info: ê° í•­ëª©ë³„ ì˜¤ë””ì˜¤ ì •ë³´
            output_dir: í”„ë¦¬ë·° ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬

        Returns:
            {
                'clips': [{'name': str, 'image': str, 'duration': float}, ...],
                'total_duration': float,
                'timeline': {...}
            }
        """
        # QuizPreviewGeneratorë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¦¬ë·° ìƒì„± (ì»´í¬ë„ŒíŠ¸ë¡œ ë¶„ë¦¬)
        preview_generator = QuizPreviewGenerator()
        return preview_generator.generate(quiz_data, audio_info, output_dir)

    def _create_idiom_intro_clip(self, duration: float = 3.0) -> VideoClip:
        """
        ì†ì–´ ë¹„êµ ëª¨ë“ˆ ì „ìš© ì¸íŠ¸ë¡œ í´ë¦½ ìƒì„± (í™”ë©´ ë¶„í•  ë””ìì¸)

        Args:
            duration: ì¸íŠ¸ë¡œ ì§€ì† ì‹œê°„ (ê¸°ë³¸ 3ì´ˆ)

        Returns:
            ì¸íŠ¸ë¡œ VideoClip
        """
        from pathlib import Path

        # ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ
        intro_bg_path = Path(__file__).parent.parent / "output" / "resources" / "images" / "idiom_intro_bg.png"

        if not intro_bg_path.exists():
            print(f"âš  ì†ì–´ ë¹„êµ ì¸íŠ¸ë¡œ ë°°ê²½ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {intro_bg_path}")
            # í´ë°±: ê¸°ë³¸ ìƒ‰ìƒ ë°°ê²½ (í™”ë©´ ë¶„í• )
            # ì™¼ìª½ (í•œêµ­ì–´ - íŒŒë€ìƒ‰)
            left_bg = ColorClip(
                size=(self.width // 2, self.height),
                color=(184, 212, 227)  # íŒŒìŠ¤í…” ë¸”ë£¨
            ).with_duration(duration).with_position((0, 0))

            # ì˜¤ë¥¸ìª½ (ì˜ì–´ - í•‘í¬ìƒ‰)
            right_bg = ColorClip(
                size=(self.width // 2, self.height),
                color=(227, 184, 196)  # íŒŒìŠ¤í…” í•‘í¬
            ).with_duration(duration).with_position((self.width // 2, 0))

            # ì¤‘ì•™ êµ¬ë¶„ì„ 
            divider = ColorClip(
                size=(5, self.height),
                color=(255, 255, 255)  # í°ìƒ‰
            ).with_duration(duration).with_position(((self.width // 2) - 2, 0))

            bg = CompositeVideoClip([left_bg, right_bg, divider], size=(self.width, self.height))
        else:
            # ë°°ê²½ ì´ë¯¸ì§€ ë¡œë“œ
            bg = ImageClip(str(intro_bg_path)).with_duration(duration)
            bg = bg.resized(height=self.height)

            # ì´ë¯¸ì§€ í¬ê¸°ê°€ widthì™€ ë§ì§€ ì•Šìœ¼ë©´ ì¡°ì •
            if bg.w != self.width:
                bg_fill = ColorClip(size=(self.width, self.height), color=(200, 200, 220)).with_duration(duration)
                bg = CompositeVideoClip([bg_fill, bg.with_position('center')], size=(self.width, self.height))

        # ë©”ì¸ íƒ€ì´í‹€ í…ìŠ¤íŠ¸ (í•˜ë‹¨ ì¤‘ì•™)
        # í°íŠ¸ ì˜ë¦¼ ë°©ì§€: size ë†’ì´ë¥¼ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìë™ ì¡°ì •
        title_txt = TextClip(
            text="í•œêµ­ì–´ ì†ì–´ vs ì›ì–´ë¯¼ ì˜ì–´ ì†ì–´",
            font_size=55,  # ì ë‹¹í•œ í¬ê¸°
            color='white',
            stroke_color='black',
            stroke_width=3,  # ì™¸ê³½ì„  (ê°€ë…ì„±)
            method='caption',  # ìë™ ì¤„ë°”ê¿ˆ ë° ë†’ì´ ì¡°ì •
            size=(self.width - 160, None),  # ì¢Œìš° ì—¬ë°± 80px, ë†’ì´ëŠ” ìë™
            font='AppleGothic',
            text_align='center'
        ).with_position(('center', 1650)).with_duration(duration)  # í•˜ë‹¨ì— ìœ„ì¹˜ (í°íŠ¸ ì˜ë¦¼ ë°©ì§€)

        # ì„œë¸Œ íƒ€ì´í‹€ (ìƒë‹¨)
        subtitle_txt = TextClip(
            text="Daily English Mecca",
            font_size=42,
            color='white',
            stroke_color='gold',
            stroke_width=3,
            method='caption',
            size=(self.width - 200, None),
            font='AppleGothic',
            text_align='center'
        ).with_position(('center', 180)).with_duration(duration)  # ìƒë‹¨ (í°íŠ¸ ì˜ë¦¼ ë°©ì§€)

        return CompositeVideoClip(
            [bg, title_txt, subtitle_txt],
            size=(self.width, self.height)
        )

    def _create_idiom_outro_clip(self, duration: float = 5.0) -> VideoClip:
        """
        ì†ì–´ ë¹„êµ ëª¨ë“ˆ ì „ìš© ì•„ì›ƒíŠ¸ë¡œ í´ë¦½ ìƒì„±

        Args:
            duration: ì•„ì›ƒíŠ¸ë¡œ ì§€ì† ì‹œê°„ (ê¸°ë³¸ 5ì´ˆ)

        Returns:
            ì•„ì›ƒíŠ¸ë¡œ VideoClip
        """
        from pathlib import Path

        # ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ
        outro_bg_path = Path(__file__).parent.parent / "output" / "resources" / "images" / "idiom_outro_bg.png"

        if not outro_bg_path.exists():
            print(f"âš  ì†ì–´ ë¹„êµ ì•„ì›ƒíŠ¸ë¡œ ë°°ê²½ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {outro_bg_path}")
            # í´ë°±: ê¸°ë³¸ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½
            bg = ColorClip(
                size=(self.width, self.height),
                color=(212, 196, 227)  # íŒŒìŠ¤í…” í¼í”Œ
            ).with_duration(duration)
        else:
            # ë°°ê²½ ì´ë¯¸ì§€ ë¡œë“œ
            bg = ImageClip(str(outro_bg_path)).with_duration(duration)
            bg = bg.resized(height=self.height)

            # ì´ë¯¸ì§€ í¬ê¸°ê°€ widthì™€ ë§ì§€ ì•Šìœ¼ë©´ ì¡°ì •
            if bg.w != self.width:
                bg_fill = ColorClip(size=(self.width, self.height), color=(240, 230, 250)).with_duration(duration)
                bg = CompositeVideoClip([bg_fill, bg.with_position('center')], size=(self.width, self.height))

        # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤ (í…ìŠ¤íŠ¸ ê°€ë…ì„±)
        text_bg = ColorClip(
            size=(self.width - 100, 600),  # ì¶©ë¶„í•œ ë†’ì´ (í°íŠ¸ ì˜ë¦¼ ë°©ì§€)
            color=(0, 0, 0)
        ).with_opacity(0.6).with_position(('center', 660)).with_duration(duration)

        # ë©”ì¸ CTA í…ìŠ¤íŠ¸
        main_txt = TextClip(
            text="ì•Œê³  ìˆë˜ ì†ì–´\nëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”!",
            font_size=62,  # í¬ê¸° ì¦ê°€
            color='white',
            stroke_color='gold',
            stroke_width=4,
            method='caption',
            size=(self.width - 160, None),  # ë†’ì´ ìë™
            font='AppleGothic',
            text_align='center'
        ).with_position(('center', 760)).with_duration(duration)  # ì¤‘ì•™ë³´ë‹¤ ì•½ê°„ ìœ„ (í°íŠ¸ ì˜ë¦¼ ë°©ì§€)

        # ì„œë¸Œ í…ìŠ¤íŠ¸
        sub_txt = TextClip(
            text="ì¢‹ì•„ìš” & êµ¬ë…",
            font_size=52,
            color='#FFD700',  # ê¸ˆìƒ‰
            stroke_color='black',
            stroke_width=3,
            method='caption',
            size=(self.width - 200, None),
            font='AppleGothic',
            text_align='center'
        ).with_position(('center', 1050)).with_duration(duration)  # í•˜ë‹¨ (í°íŠ¸ ì˜ë¦¼ ë°©ì§€)

        return CompositeVideoClip(
            [bg, text_bg, main_txt, sub_txt],
            size=(self.width, self.height)
        )

    def _create_idiom_korean_intro_clip(
        self,
        korean_idiom: str,
        korean_meaning: str,
        duration: float,
        background_image_path: str = None
    ) -> VideoClip:
        """
        í•œêµ­ì–´ ì†ì–´ ì†Œê°œ í´ë¦½ ìƒì„±

        Args:
            korean_idiom: í•œêµ­ì–´ ì†ì–´ (ì˜ˆ: 'ëŒ€ë°•')
            korean_meaning: í•œêµ­ì–´ ì˜ë¯¸ ì„¤ëª…
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            background_image_path: DALL-E ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒì‚¬í•­)

        Returns:
            í•œêµ­ì–´ ì†Œê°œ VideoClip
        """
        # ë°°ê²½ (DALL-E ì´ë¯¸ì§€ ë˜ëŠ” ê¸°ë³¸ ìƒ‰ìƒ)
        if background_image_path and os.path.exists(background_image_path):
            bg = ImageClip(background_image_path).resized(
                height=self.height
            ).with_duration(duration)
            # ì¤‘ì•™ í¬ë¡­ (9:16 ë¹„ìœ¨)
            bg = bg.with_position(('center', 'center')).cropped(
                x_center=bg.w // 2,
                width=self.width,
                height=self.height
            )
        else:
            # ê¸°ë³¸ ë°°ê²½ (íŒŒìŠ¤í…” ë¸”ë£¨)
            bg = ColorClip(
                size=(self.width, self.height),
                color=(184, 212, 227)
            ).with_duration(duration)

        # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤
        text_bg = ColorClip(
            size=(self.width - 120, 700),  # ì¶©ë¶„í•œ ë†’ì´
            color=(255, 255, 255)
        ).with_opacity(0.85).with_position(('center', 610)).with_duration(duration)

        # í•œêµ­ì–´ ì†ì–´ (í° í…ìŠ¤íŠ¸)
        idiom_txt = TextClip(
            text=f'"{korean_idiom}"',
            font_size=90,
            color='#2E5090',  # ì§™ì€ íŒŒë€ìƒ‰
            stroke_color='white',
            stroke_width=2,
            method='caption',
            size=(self.width - 180, None),
            font='AppleGothic',
            text_align='center'
        ).with_position(('center', 700)).with_duration(duration)

        # ì˜ë¯¸ ì„¤ëª… (ì‘ì€ í…ìŠ¤íŠ¸)
        meaning_txt = TextClip(
            text=korean_meaning,
            font_size=42,
            color='#4A4A4A',  # íšŒìƒ‰
            method='caption',
            size=(self.width - 200, None),
            font='AppleGothic',
            text_align='center'
        ).with_position(('center', 950)).with_duration(duration)

        # ìƒë‹¨ ë¼ë²¨
        label_txt = TextClip(
            text="ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì†ì–´",
            font_size=45,
            color='white',
            stroke_color='#2E5090',
            stroke_width=3,
            method='caption',
            size=(self.width - 200, None),
            font='AppleGothic',
            text_align='center'
        ).with_position(('center', 420)).with_duration(duration)

        return CompositeVideoClip(
            [bg, text_bg, label_txt, idiom_txt, meaning_txt],
            size=(self.width, self.height)
        )

    def _create_idiom_wrong_clip(
        self,
        wrong_translation: str,
        why_wrong: str,
        duration: float,
        background_image_path: str = None
    ) -> VideoClip:
        """
        í‹€ë¦° ë²ˆì—­ í´ë¦½ ìƒì„± (í™”ë©´ ë¶„í• )

        Args:
            wrong_translation: í‹€ë¦° ì˜ì–´ ë²ˆì—­
            why_wrong: ì™œ í‹€ë ¸ëŠ”ì§€ ì„¤ëª…
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            background_image_path: DALL-E ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒì‚¬í•­)

        Returns:
            í‹€ë¦° ë²ˆì—­ VideoClip
        """
        # ë°°ê²½ (DALL-E ì´ë¯¸ì§€ ë˜ëŠ” ê¸°ë³¸ ìƒ‰ìƒ)
        if background_image_path and os.path.exists(background_image_path):
            bg = ImageClip(background_image_path).resized(
                height=self.height
            ).with_duration(duration)
            # ì¤‘ì•™ í¬ë¡­ (9:16 ë¹„ìœ¨)
            bg = bg.with_position(('center', 'center')).cropped(
                x_center=bg.w // 2,
                width=self.width,
                height=self.height
            )
            clips = [bg]
        else:
            # ê¸°ë³¸ ë°°ê²½ (ë¶„í•  í™”ë©´ - ì™¼ìª½ ë ˆë“œ, ì˜¤ë¥¸ìª½ ì˜ë¡œìš°)
            left_bg = ColorClip(
                size=(self.width // 2, self.height),
                color=(230, 150, 150)  # íŒŒìŠ¤í…” ë ˆë“œ
            ).with_duration(duration).with_position((0, 0))

            right_bg = ColorClip(
                size=(self.width // 2, self.height),
                color=(250, 240, 180)  # íŒŒìŠ¤í…” ì˜ë¡œìš°
            ).with_duration(duration).with_position((self.width // 2, 0))

            clips = [left_bg, right_bg]

        # ì¤‘ì•™ êµ¬ë¶„ì„ 
        divider = ColorClip(
            size=(5, self.height),
            color=(100, 100, 100)
        ).with_duration(duration).with_position(((self.width // 2) - 2, 0))

        # ì™¼ìª½: í‹€ë¦° í‘œí˜„
        wrong_txt = TextClip(
            text=f'âŒ\n{wrong_translation}',
            font_size=52,
            color='#8B0000',  # ë‹¤í¬ ë ˆë“œ
            stroke_color='white',
            stroke_width=2,
            method='caption',
            size=(self.width // 2 - 80, None),
            font='AppleGothic',
            text_align='center'
        ).with_position((40, 650)).with_duration(duration)

        # ì™¼ìª½ ë¼ë²¨
        left_label = TextClip(
            text="í‹€ë¦° ë²ˆì—­",
            font_size=38,
            color='white',
            stroke_color='#8B0000',
            stroke_width=2,
            method='caption',
            size=(self.width // 2 - 80, None),
            font='AppleGothic',
            text_align='center'
        ).with_position((40, 450)).with_duration(duration)

        # ì˜¤ë¥¸ìª½: ì„¤ëª…
        why_txt = TextClip(
            text=f'ğŸ’¡ ì™œ?\n\n{why_wrong}',
            font_size=38,
            color='#4A4A4A',
            method='caption',
            size=(self.width // 2 - 100, None),
            font='AppleGothic',
            text_align='center'
        ).with_position((self.width // 2 + 50, 600)).with_duration(duration)

        # ì˜¤ë¥¸ìª½ ë¼ë²¨
        right_label = TextClip(
            text="ì„¤ëª…",
            font_size=38,
            color='#4A4A4A',
            stroke_color='white',
            stroke_width=2,
            method='caption',
            size=(self.width // 2 - 100, None),
            font='AppleGothic',
            text_align='center'
        ).with_position((self.width // 2 + 50, 450)).with_duration(duration)

        # í…ìŠ¤íŠ¸ ìš”ì†Œë“¤ ì¶”ê°€
        clips.extend([divider, left_label, wrong_txt, right_label, why_txt])

        return CompositeVideoClip(
            clips,
            size=(self.width, self.height)
        )

    def _create_idiom_correct_clip(
        self,
        correct_expressions: list[dict],
        duration: float,
        background_image_path: str = None
    ) -> VideoClip:
        """
        ì˜¬ë°”ë¥¸ í‘œí˜„ë“¤ í´ë¦½ ìƒì„± (3ê°œ í‘œí˜„)

        Args:
            correct_expressions: ì˜¬ë°”ë¥¸ í‘œí˜„ ë¦¬ìŠ¤íŠ¸ (3ê°œ)
                [
                    {
                        'english': str,
                        'usage_level': str,
                        'korean_label': str,
                        'example': str
                    },
                    ...
                ]
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            background_image_path: DALL-E ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒì‚¬í•­)

        Returns:
            ì˜¬ë°”ë¥¸ í‘œí˜„ VideoClip
        """
        # ë°°ê²½ (DALL-E ì´ë¯¸ì§€ ë˜ëŠ” ê¸°ë³¸ ìƒ‰ìƒ)
        if background_image_path and os.path.exists(background_image_path):
            bg = ImageClip(background_image_path).resized(
                height=self.height
            ).with_duration(duration)
            # ì¤‘ì•™ í¬ë¡­ (9:16 ë¹„ìœ¨)
            bg = bg.with_position(('center', 'center')).cropped(
                x_center=bg.w // 2,
                width=self.width,
                height=self.height
            )
        else:
            # ê¸°ë³¸ ë°°ê²½ (íŒŒìŠ¤í…” ê·¸ë¦°)
            bg = ColorClip(
                size=(self.width, self.height),
                color=(180, 230, 180)
            ).with_duration(duration)

        # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤
        text_bg = ColorClip(
            size=(self.width - 100, 1100),  # ì¶©ë¶„í•œ ë†’ì´ (3ê°œ í‘œí˜„)
            color=(255, 255, 255)
        ).with_opacity(0.9).with_position(('center', 460)).with_duration(duration)

        # ìƒë‹¨ ë¼ë²¨ (ì´ëª¨ì§€ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ)
        label_txt = TextClip(
            text="ì˜¬ë°”ë¥¸ í‘œí˜„",
            font_size=50,
            color='white',
            stroke_color='#2E7D32',  # ë‹¤í¬ ê·¸ë¦°
            stroke_width=4,
            method='caption',
            size=(self.width - 160, None),
            font='AppleGothic',
            text_align='center'
        ).with_position(('center', 320)).with_duration(duration)

        clips = [bg, text_bg, label_txt]

        # 3ê°œ í‘œí˜„ì„ ì„¸ë¡œë¡œ ë°°ì¹˜ (ê°„ê²©ì„ ë„“í˜€ì„œ ì˜ˆë¬¸ ê³µê°„ í™•ë³´)
        y_positions = [500, 900, 1300]  # ê°„ê²© 400px

        for idx, expr in enumerate(correct_expressions[:3]):  # ìµœëŒ€ 3ê°œ
            english = expr['english']
            korean_label = expr['korean_label']
            usage_level = expr['usage_level']
            example = expr.get('example', '')  # ì˜ˆë¬¸ ì¶”ê°€

            # ì‚¬ìš© ìˆ˜ì¤€ë³„ ìƒ‰ìƒ
            level_colors = {
                'informal': '#1976D2',  # íŒŒë€ìƒ‰
                'formal': '#7B1FA2',    # ë³´ë¼ìƒ‰
                'slang': '#F57C00'      # ì£¼í™©ìƒ‰
            }
            color = level_colors.get(usage_level, '#4A4A4A')

            # ì˜ì–´ í‘œí˜„ í…ìŠ¤íŠ¸ (ë²ˆí˜¸ + ì˜ì–´)
            expr_txt = TextClip(
                text=f'{idx + 1}. {english}',
                font_size=48,
                color=color,
                stroke_color='white',
                stroke_width=2,
                method='caption',
                size=(self.width - 160, None),
                font='AppleGothic',
                text_align='center'
            ).with_position(('center', y_positions[idx])).with_duration(duration)

            # í•œêµ­ì–´ ë¼ë²¨ (ì‚¬ìš© ìˆ˜ì¤€)
            label = TextClip(
                text=f'({korean_label})',
                font_size=34,
                color='#666666',
                method='caption',
                size=(self.width - 180, None),
                font='AppleGothic',
                text_align='center'
            ).with_position(('center', y_positions[idx] + 70)).with_duration(duration)

            clips.extend([expr_txt, label])

            # ì˜ˆë¬¸ ì¶”ê°€ (ë” ì‘ê³  íšŒìƒ‰ìœ¼ë¡œ)
            if example:
                example_txt = TextClip(
                    text=f'ì˜ˆ: {example}',
                    font_size=30,
                    color='#888888',
                    method='caption',
                    size=(self.width - 200, None),
                    font='AppleGothic',
                    text_align='center'
                ).with_position(('center', y_positions[idx] + 130)).with_duration(duration)
                clips.append(example_txt)

        return CompositeVideoClip(clips, size=(self.width, self.height))

    def create_idiom_comparison_video(
        self,
        idiom_data: dict,
        audio_info: list[dict],
        output_path: str
    ):
        """
        ì†ì–´ ë¹„êµ ë¹„ë””ì˜¤ ìƒì„± (ì „ì²´ íŒŒì´í”„ë¼ì¸)

        Args:
            idiom_data: ì†ì–´ ë¹„êµ ë°ì´í„°
                {
                    'format': 'idiom_comparison',
                    'korean_idiom': str,
                    'korean_meaning': str,
                    'wrong_translation': str,
                    'why_wrong': str,
                    'correct_expressions': [...]
                }
            audio_info: 5ê°œ í•­ëª©ì˜ ì˜¤ë””ì˜¤ ì •ë³´
                [
                    {'sentence': str, 'voices': {'alloy': {...}, ...}},  # í•œêµ­ì–´ ì†ì–´
                    {...},  # í‹€ë¦° ë²ˆì—­
                    {...},  # ì˜¬ë°”ë¥¸ í‘œí˜„ 1
                    {...},  # ì˜¬ë°”ë¥¸ í‘œí˜„ 2
                    {...}   # ì˜¬ë°”ë¥¸ í‘œí˜„ 3
                ]
            output_path: ë¹„ë””ì˜¤ ì €ì¥ ê²½ë¡œ
        """
        print("=" * 60)
        print("ì†ì–´ ë¹„êµ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘")
        print("=" * 60)

        # 0. ì´ë¯¸ì§€ ìƒì„± (DALL-E 3)
        image_paths = {}
        if 'image_prompts' in idiom_data and self.image_generator:
            print("0. DALL-E ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
            prompts = idiom_data['image_prompts']

            # í•œêµ­ì–´ ì¸íŠ¸ë¡œ ì´ë¯¸ì§€
            print("   - í•œêµ­ì–´ ì¸íŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„±...")
            korean_image_path = self.image_generator.resource_manager.get_image_path(
                f"idiom_korean_{idiom_data.get('id', 'temp')}"
            )
            image_paths['korean_intro'] = self.image_generator.generate_image(
                prompt=prompts['korean_intro'],
                output_path=korean_image_path
            )

            # í‹€ë¦° ë²ˆì—­ ì´ë¯¸ì§€
            print("   - í‹€ë¦° ë²ˆì—­ ì´ë¯¸ì§€ ìƒì„±...")
            wrong_image_path = self.image_generator.resource_manager.get_image_path(
                f"idiom_wrong_{idiom_data.get('id', 'temp')}"
            )
            image_paths['wrong'] = self.image_generator.generate_image(
                prompt=prompts['wrong'],
                output_path=wrong_image_path
            )

            # ì˜¬ë°”ë¥¸ í‘œí˜„ ì´ë¯¸ì§€
            print("   - ì˜¬ë°”ë¥¸ í‘œí˜„ ì´ë¯¸ì§€ ìƒì„±...")
            correct_image_path = self.image_generator.resource_manager.get_image_path(
                f"idiom_correct_{idiom_data.get('id', 'temp')}"
            )
            image_paths['correct'] = self.image_generator.generate_image(
                prompt=prompts['correct'],
                output_path=correct_image_path
            )

            print(f"   âœ“ 3ê°œ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
        else:
            print("   âš  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì—†ìŒ - ê¸°ë³¸ ë°°ê²½ìƒ‰ ì‚¬ìš©")

        all_clips = []
        current_time = 0.0

        # 1. ì¸íŠ¸ë¡œ í´ë¦½ (3ì´ˆ)
        print("1. ì¸íŠ¸ë¡œ í´ë¦½ ìƒì„± ì¤‘...")
        intro_clip = self._create_idiom_intro_clip(duration=3.0)
        intro_clip = intro_clip.with_start(current_time)
        all_clips.append(intro_clip)
        current_time += 3.0

        # 2. í•œêµ­ì–´ ì†ì–´ ì†Œê°œ í´ë¦½
        print("2. í•œêµ­ì–´ ì†ì–´ ì†Œê°œ í´ë¦½ ìƒì„± ì¤‘...")
        korean_duration = audio_info[0]['voices']['alloy']['duration'] + 2.0  # ê°„ê²© 2ì´ˆ
        korean_clip = self._create_idiom_korean_intro_clip(
            korean_idiom=idiom_data['korean_idiom'],
            korean_meaning=idiom_data['korean_meaning'],
            duration=korean_duration,
            background_image_path=image_paths.get('korean_intro')  # DALL-E ë°°ê²½ ì´ë¯¸ì§€
        )
        korean_clip = korean_clip.with_start(current_time)
        all_clips.append(korean_clip)
        current_time += korean_duration

        # 3. í‹€ë¦° ë²ˆì—­ í´ë¦½
        print("3. í‹€ë¦° ë²ˆì—­ í´ë¦½ ìƒì„± ì¤‘...")
        wrong_duration = audio_info[1]['voices']['alloy']['duration'] + 2.0  # ê°„ê²© 2ì´ˆ
        wrong_clip = self._create_idiom_wrong_clip(
            wrong_translation=idiom_data['wrong_translation'],
            why_wrong=idiom_data['why_wrong'],
            duration=wrong_duration,
            background_image_path=image_paths.get('wrong')  # DALL-E ë°°ê²½ ì´ë¯¸ì§€
        )
        wrong_clip = wrong_clip.with_start(current_time)
        all_clips.append(wrong_clip)
        current_time += wrong_duration

        # 4. ì˜¬ë°”ë¥¸ í‘œí˜„ë“¤ í´ë¦½ (3ê°œ í‘œí˜„ì„ í•˜ë‚˜ì˜ í´ë¦½ì—)
        print("4. ì˜¬ë°”ë¥¸ í‘œí˜„ë“¤ í´ë¦½ ìƒì„± ì¤‘...")
        # 3ê°œ ì˜¤ë””ì˜¤ duration í•©ê³„ + ê°„ê²©
        correct_duration = sum(
            audio_info[i]['voices']['alloy']['duration']
            for i in range(2, 5)  # ì¸ë±ìŠ¤ 2, 3, 4
        ) + 2.0  # ê°„ê²©
        correct_clip = self._create_idiom_correct_clip(
            correct_expressions=idiom_data['correct_expressions'],
            duration=correct_duration,
            background_image_path=image_paths.get('correct')  # DALL-E ë°°ê²½ ì´ë¯¸ì§€
        )
        correct_clip = correct_clip.with_start(current_time)
        all_clips.append(correct_clip)
        current_time += correct_duration

        # 5. ì•„ì›ƒíŠ¸ë¡œ í´ë¦½ (5ì´ˆ)
        print("5. ì•„ì›ƒíŠ¸ë¡œ í´ë¦½ ìƒì„± ì¤‘...")
        outro_clip = self._create_idiom_outro_clip(duration=5.0)
        outro_clip = outro_clip.with_start(current_time)
        all_clips.append(outro_clip)
        current_time += 5.0

        # ë¹„ë””ì˜¤ í•©ì„±
        print("6. ë¹„ë””ì˜¤ í´ë¦½ í•©ì„± ì¤‘...")
        final_video = CompositeVideoClip(all_clips, size=(self.width, self.height))
        final_video = final_video.with_duration(current_time)

        # ì˜¤ë””ì˜¤ íŠ¸ë™ ìƒì„± (5ê°œ ìŒì„±)
        print("7. ì˜¤ë””ì˜¤ íŠ¸ë™ í•©ì„± ì¤‘...")
        audio_clips = []
        audio_start_times = [
            3.0,  # ì¸íŠ¸ë¡œ í›„
            3.0 + korean_duration,  # í•œêµ­ì–´ ì†Œê°œ í›„
            3.0 + korean_duration + wrong_duration,  # í‹€ë¦° ë²ˆì—­ í›„
            3.0 + korean_duration + wrong_duration,  # ì˜¬ë°”ë¥¸ í‘œí˜„ 1
            3.0 + korean_duration + wrong_duration,  # ì˜¬ë°”ë¥¸ í‘œí˜„ 2-3 (ì‹œì‘ ì‹œê°„ ë™ì¼, durationìœ¼ë¡œ ì¡°ì •)
        ]

        # ê° ì˜¤ë””ì˜¤ í´ë¦½ ì¶”ê°€ (alloy, nova, shimmer ìˆœí™˜)
        voices = ['alloy', 'nova', 'shimmer']
        for i, info in enumerate(audio_info[:5]):  # 5ê°œë§Œ
            voice = voices[i % 3]  # ìŒì„± ìˆœí™˜
            audio_path = info['voices'][voice]['path']
            audio_clip = AudioFileClip(audio_path)

            # ì˜¬ë°”ë¥¸ í‘œí˜„ 3ê°œëŠ” ìˆœì°¨ì ìœ¼ë¡œ ì¬ìƒ
            if i >= 2:  # ì¸ë±ìŠ¤ 2, 3, 4 (ì˜¬ë°”ë¥¸ í‘œí˜„)
                # ì´ì „ ì˜¤ë””ì˜¤ë“¤ì˜ duration í•©ì‚°
                accumulated_duration = sum(
                    audio_info[j]['voices'][voices[j % 3]]['duration']
                    for j in range(2, i)
                )
                start_time = audio_start_times[2] + accumulated_duration
            else:
                start_time = audio_start_times[i]

            audio_clip = audio_clip.with_start(start_time)
            audio_clips.append(audio_clip)

        # ë°°ê²½ ìŒì•… ì¶”ê°€ (ì¸íŠ¸ë¡œ 3ì´ˆì—ë§Œ)
        background_music_path = None
        if self.resource_manager:
            bg_music_candidates = [
                os.path.join(str(self.resource_manager.resources_dir), "background_music_original.mp3"),
                os.path.join(str(self.resource_manager.resources_dir), "background_music.mp3"),
            ]
            for path in bg_music_candidates:
                if os.path.exists(path):
                    background_music_path = path
                    break

        if background_music_path:
            try:
                print(f"ë°°ê²½ ìŒì•… ì¶”ê°€: {background_music_path}")
                bg_music = AudioFileClip(background_music_path)
                bg_music = bg_music * 0.05  # ë³¼ë¥¨ 5%
                bg_music = bg_music.subclipped(0, 3.0)  # ì¸íŠ¸ë¡œ 3ì´ˆë§Œ
                bg_music = bg_music.with_start(0)
                audio_clips.append(bg_music)
            except Exception as e:
                print(f"âš  ë°°ê²½ ìŒì•… ì¶”ê°€ ì‹¤íŒ¨: {e}")

        # ìµœì¢… ì˜¤ë””ì˜¤ í•©ì„±
        if audio_clips:
            combined_audio = CompositeAudioClip(audio_clips)
            final_video = final_video.with_audio(combined_audio)

        # íŒŒì¼ ì €ì¥
        print(f"8. ë¹„ë””ì˜¤ íŒŒì¼ ì €ì¥ ì¤‘: {output_path}")
        final_video.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',
            temp_audiofile='temp-audio.m4a',
            remove_temp=True,
            logger=None  # ë¡œê·¸ ì¶œë ¥ ìµœì†Œí™”
        )

        print("=" * 60)
        print("ì†ì–´ ë¹„êµ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
        print(f"ì´ ê¸¸ì´: {current_time:.1f}ì´ˆ")
        print("=" * 60)

    def create_longform_video(
        self,
        sentences: list[str],
        image_paths: list[str],
        audio_info: list[dict],
        output_path: str,
        image_groups: list[int],
        translations: list[str],
        hook_phrase: str = None,
        kelly_style: str = 'casual_hoodie'
    ) -> str:
        """
        ë¡±í¼ êµìœ¡ ë¹„ë””ì˜¤ ìƒì„± - Shorts í™•ì¥íŒ (16:9 ê°€ë¡œ, 3-4ë¶„)

        ê° ë¬¸ì¥ì„ 3ë²ˆ ë°˜ë³µ (alloy, nova, shimmer)í•˜ì—¬ í•™ìŠµ íš¨ê³¼ ê·¹ëŒ€í™”
        KellyëŠ” ì¸íŠ¸ë¡œ/ì•„ì›ƒíŠ¸ë¡œì—ë§Œ ë“±ì¥ (ë¸Œëœë”©)

        Args:
            sentences: 3ê°œì˜ ì˜ì–´ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ (Shortsì™€ ë™ì¼)
            image_paths: ë¬¸ì¥ë³„ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (3ê°œ)
            audio_info: ê° ë¬¸ì¥ë³„ ì˜¤ë””ì˜¤ ì •ë³´ [{'sentence': str, 'voices': {...}}, ...]
            output_path: ë¹„ë””ì˜¤ ì €ì¥ ê²½ë¡œ
            image_groups: ì´ë¯¸ì§€ ê·¸ë£¹ ì •ë³´
            translations: 3ê°œì˜ í•œê¸€ ë²ˆì—­ ë¦¬ìŠ¤íŠ¸
            hook_phrase: AI ìƒì„± í›… ë¬¸êµ¬ (ì„ íƒì‚¬í•­)
            kelly_style: Kelly ìºë¦­í„° ìŠ¤íƒ€ì¼ (casual_hoodie, business, etc.)

        Returns:
            ìƒì„±ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        try:
            print("\n" + "=" * 80)
            print("ğŸ¬ ë¡±í¼ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘ (16:9, 3ë¬¸ì¥ Ã— 3ë²ˆ ë°˜ë³µ)")
            print("=" * 80)

            # Kelly ì´ë¯¸ì§€ ë¡œë“œ (ë¡±í¼ì—ì„œë„ Kelly ìºë¦­í„° ì‚¬ìš©)
            kelly_image_path = None
            if self.resource_manager:
                kelly_candidates = [
                    os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_casual_hoodie.png"),
                    os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_ponytail.png"),
                    os.path.join(str(self.resource_manager.resources_dir), "images", "kelly_glasses.png"),
                ]
                for path in kelly_candidates:
                    if os.path.exists(path):
                        kelly_image_path = path
                        print(f"âœ“ Kelly ì´ë¯¸ì§€ ë¡œë“œ: {os.path.basename(path)}")
                        break

            if not kelly_image_path:
                print("âš  Kelly ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")

            all_clips = []
            audio_clips = []
            current_time = 0.0

            # 1. ì¸íŠ¸ë¡œ (5ì´ˆ) - Kelly í¬í•¨
            print("\n[1/11] ì¸íŠ¸ë¡œ í´ë¦½ ìƒì„± ì¤‘...")
            intro_clip = self._create_longform_intro_clip(
                duration=5.0,
                kelly_image_path=kelly_image_path
            )
            all_clips.append(intro_clip)
            current_time += 5.0
            print("âœ“ ì¸íŠ¸ë¡œ í´ë¦½ ì™„ë£Œ (5.0ì´ˆ)")

            # 2. 3ê°œ ë¬¸ì¥ Ã— 3ë²ˆ ë°˜ë³µ = 9ê°œ í´ë¦½
            print("\n[2-10/11] ë¬¸ì¥ í´ë¦½ ìƒì„± ì¤‘ (ê° ë¬¸ì¥ 3ë²ˆ ë°˜ë³µ)...")
            for i in range(min(3, len(sentences))):
                sentence = sentences[i]
                translation = translations[i] if i < len(translations) else ""
                image_path = image_paths[i] if i < len(image_paths) else None

                print(f"[DEBUG ë¡±í¼] ë¬¸ì¥ {i+1} ì´ë¯¸ì§€ ê²½ë¡œ: {image_path}")
                print(f"[DEBUG ë¡±í¼] íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(image_path) if image_path else False}")

                if not image_path or not os.path.exists(image_path):
                    print(f"âš ï¸ ë¬¸ì¥ {i+1} ì´ë¯¸ì§€ ì—†ìŒ, ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue

                # 3ë²ˆ ë°˜ë³µ: alloy â†’ nova â†’ shimmer
                for voice_name in ['alloy', 'nova', 'shimmer']:
                    if i < len(audio_info):
                        audio_data = audio_info[i]['voices'].get(voice_name)
                        if audio_data:
                            audio_path = audio_data['path']
                            duration = audio_data['duration'] + 2.0  # 2ì´ˆ ê°„ê²© (ë”°ë¼ ë§í•˜ê¸° ì‹œê°„)

                            # Longform ë°©ì‹ í´ë¦½ ìƒì„± (16:9 ê°€ë¡œ ì´ë¯¸ì§€)
                            sentence_clip = self._create_sentence_clip(
                                image_path=image_path,
                                sentences=[sentence],
                                translations=[translation],
                                duration=duration,
                                format_type="longform"
                            )
                            all_clips.append(sentence_clip)

                            # ì˜¤ë””ì˜¤ í´ë¦½ ì¶”ê°€
                            audio_clip = AudioFileClip(audio_path).with_start(current_time)
                            audio_clips.append(audio_clip)

                            current_time += duration
                            print(f"âœ“ ë¬¸ì¥ {i+1}/10 - {voice_name} ì™„ë£Œ ({duration:.1f}ì´ˆ)")
                        else:
                            print(f"âš ï¸ ë¬¸ì¥ {i+1} {voice_name} ì˜¤ë””ì˜¤ ì—†ìŒ")
                    else:
                        print(f"âš ï¸ ë¬¸ì¥ {i+1} ì˜¤ë””ì˜¤ ì •ë³´ ì—†ìŒ")

            # 3. ì•„ì›ƒíŠ¸ë¡œ (5ì´ˆ) - Kelly í¬í•¨
            print("\n[11/11] ì•„ì›ƒíŠ¸ë¡œ í´ë¦½ ìƒì„± ì¤‘...")
            outro_clip = self._create_longform_outro_clip(
                duration=5.0,
                kelly_image_path=kelly_image_path
            )
            all_clips.append(outro_clip)
            print("âœ“ ì•„ì›ƒíŠ¸ë¡œ í´ë¦½ ì™„ë£Œ (5.0ì´ˆ)")

            # 4. ëª¨ë“  ë¹„ë””ì˜¤ í´ë¦½ ì—°ê²°
            print("\në¹„ë””ì˜¤ í´ë¦½ ì—°ê²° ì¤‘...")
            final_video = concatenate_videoclips(all_clips, method="compose")

            # 5. ì˜¤ë””ì˜¤ í•©ì„±
            print("ì˜¤ë””ì˜¤ í•©ì„± ì¤‘...")
            if audio_clips:
                combined_audio = CompositeAudioClip(audio_clips)

                # ë°°ê²½ ìŒì•… ì¶”ê°€ (ì¸íŠ¸ë¡œ 5ì´ˆì—ë§Œ)
                background_music_path = None
                if self.resource_manager:
                    bg_music_candidates = [
                        os.path.join(str(self.resource_manager.resources_dir), "background_music_original.mp3"),
                        os.path.join(str(self.resource_manager.resources_dir), "background_music.mp3"),
                    ]
                    for path in bg_music_candidates:
                        if os.path.exists(path):
                            background_music_path = path
                            break

                if background_music_path:
                    try:
                        print(f"ë°°ê²½ ìŒì•… ì¶”ê°€: {background_music_path}")
                        bg_music = AudioFileClip(background_music_path)
                        bg_music = bg_music * 0.05  # ë³¼ë¥¨ 5% (TTS ë°©í•´ ì•ˆ í•¨)
                        bg_music = bg_music.subclipped(0, 5.0)  # ì¸íŠ¸ë¡œ 5ì´ˆë§Œ
                        bg_music = bg_music.with_start(0)
                        combined_audio = CompositeAudioClip([combined_audio, bg_music])
                        print("âœ“ ë°°ê²½ ìŒì•… ì¶”ê°€ ì™„ë£Œ (ì¸íŠ¸ë¡œ 5ì´ˆ)")
                    except Exception as e:
                        print(f"âš  ë°°ê²½ ìŒì•… ì¶”ê°€ ì‹¤íŒ¨: {e}")

                final_video = final_video.with_audio(combined_audio)
            else:
                print("âš ï¸ ì˜¤ë””ì˜¤ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")

            # 6. ë¹„ë””ì˜¤ ì €ì¥
            total_duration = final_video.duration
            print(f"\në¹„ë””ì˜¤ ì €ì¥ ì¤‘... (ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ = {total_duration/60:.1f}ë¶„)")
            print(f"ì¶œë ¥ ê²½ë¡œ: {output_path}")

            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                preset='medium',
                threads=4
            )

            print("\n" + "=" * 80)
            print("âœ… ë¡±í¼ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
            print(f"ğŸ“Š í†µê³„:")
            print(f"   - ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)")
            print(f"   - í•´ìƒë„: {self.width}x{self.height} (16:9)")
            print(f"   - ë¬¸ì¥ ìˆ˜: 3ê°œ Ã— 3ë²ˆ ë°˜ë³µ = 9ê°œ í´ë¦½")
            print(f"   - Kelly: ì¸íŠ¸ë¡œ/ì•„ì›ƒíŠ¸ë¡œë§Œ (ë¸Œëœë”©)")
            print(f"   - í•™ìŠµ ë°©ì‹: Shorts ë™ì¼ (3ë²ˆ ë°˜ë³µ)")
            print("=" * 80)

            return output_path

        except Exception as e:
            print(f"\nâŒ ë¡±í¼ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
