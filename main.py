#!/usr/bin/env python3
"""
Daily English Mecca - ìœ íŠœë¸Œ ì‡¼ì¸  ìë™ ìƒì„± í”„ë¡œê·¸ë¨
í•˜ë£¨ 3ë¬¸ì¥ ì˜ì–´ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ìë™ìœ¼ë¡œ ì œì‘í•©ë‹ˆë‹¤.
"""

import os
import sys
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

from src.content_analyzer import ContentAnalyzer
from src.image_generator import ImageGenerator
from src.tts_generator import TTSGenerator
from src.video_creator import VideoCreator
from src.youtube_metadata import YouTubeMetadataGenerator


def print_banner():
    """í”„ë¡œê·¸ë¨ ë°°ë„ˆ ì¶œë ¥"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘   Daily English Mecca                         â•‘
    â•‘   ë§¤ì¼ 3ë¬¸ì¥ ì˜ì–´ í•™ìŠµ ì‡¼ì¸  ìë™ ìƒì„±ê¸°      â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


def get_sentences_from_user() -> list[str]:
    """
    ì‚¬ìš©ìë¡œë¶€í„° 3ê°œì˜ ì˜ì–´ ë¬¸ì¥ ì…ë ¥ë°›ê¸°

    Returns:
        ì˜ì–´ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
    """
    print("\nğŸ“ ì˜¤ëŠ˜ì˜ 3ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:\n")

    sentences = []
    for i in range(3):
        while True:
            sentence = input(f"ë¬¸ì¥ {i+1}: ").strip()
            if sentence:
                sentences.append(sentence)
                break
            else:
                print("âŒ ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    print("\nâœ… ì…ë ¥ëœ ë¬¸ì¥:")
    for i, s in enumerate(sentences):
        print(f"  {i+1}. {s}")

    return sentences


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("\nâŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì„ ìƒì„±í•˜ê³  API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        print("   ì˜ˆì‹œ: OPENAI_API_KEY=your_api_key_here\n")
        sys.exit(1)

    # ë°°ë„ˆ ì¶œë ¥
    print_banner()

    # ë¬¸ì¥ ì…ë ¥ ë°›ê¸°
    sentences = get_sentences_from_user()

    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    output_dir = Path("output")
    images_dir = output_dir / "images" / timestamp
    audio_dir = output_dir / "audio" / timestamp
    videos_dir = output_dir / "videos"
    metadata_dir = output_dir / "metadata"

    # ë””ë ‰í† ë¦¬ ìƒì„±
    for dir_path in [images_dir, audio_dir, videos_dir, metadata_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)

    try:
        # 1. ì½˜í…ì¸  ë¶„ì„
        print("\n" + "="*50)
        print("1ï¸âƒ£  ë¬¸ì¥ ë¶„ì„ ì¤‘...")
        print("="*50)

        analyzer = ContentAnalyzer(api_key=api_key)
        analysis = analyzer.analyze_sentences(sentences)

        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"   - ìƒì„±í•  ì´ë¯¸ì§€ ê°œìˆ˜: {analysis['num_images']}ê°œ")
        print(f"   - ì´ë¯¸ì§€ ê·¸ë£¹: {analysis['image_groups']}")

        # 2. ì´ë¯¸ì§€ ìƒì„±
        print("\n" + "="*50)
        print("2ï¸âƒ£  ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        print("="*50)

        image_gen = ImageGenerator(api_key=api_key)
        image_paths = []

        for idx, prompt in enumerate(analysis['prompts']):
            img_path = images_dir / f"image_{idx+1}.png"
            image_path = image_gen.generate_image(
                prompt=prompt,
                output_path=str(img_path)
            )
            image_paths.append(image_path)

        # 3. ìŒì„± ìƒì„±
        print("\n" + "="*50)
        print("3ï¸âƒ£  ìŒì„± ìƒì„± ì¤‘...")
        print("="*50)

        tts_gen = TTSGenerator(api_key=api_key)
        audio_path = audio_dir / "speech.mp3"

        tts_gen.generate_speech_for_sentences(
            sentences=sentences,
            output_path=str(audio_path),
            voice="nova",
            add_pauses=True
        )

        audio_duration = tts_gen.get_audio_duration(str(audio_path))
        print(f"   - ìŒì„± ê¸¸ì´: {audio_duration:.1f}ì´ˆ")

        # 4. ë¹„ë””ì˜¤ ìƒì„±
        print("\n" + "="*50)
        print("4ï¸âƒ£  ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
        print("="*50)

        video_creator = VideoCreator()
        video_path = videos_dir / f"daily_english_{timestamp}.mp4"

        video_creator.create_video(
            sentences=sentences,
            image_paths=image_paths,
            audio_path=str(audio_path),
            output_path=str(video_path),
            image_groups=analysis['image_groups']
        )

        # 5. ìœ íŠœë¸Œ ë©”íƒ€ì •ë³´ ìƒì„±
        print("\n" + "="*50)
        print("5ï¸âƒ£  ìœ íŠœë¸Œ ë©”íƒ€ì •ë³´ ìƒì„± ì¤‘...")
        print("="*50)

        metadata_gen = YouTubeMetadataGenerator(api_key=api_key)
        metadata = metadata_gen.generate_metadata(sentences)

        # ë©”íƒ€ì •ë³´ ì €ì¥
        metadata_path = metadata_dir / f"metadata_{timestamp}.json"
        metadata_gen.save_metadata(metadata, str(metadata_path))

        # ë©”íƒ€ì •ë³´ ì¶œë ¥
        metadata_gen.print_metadata(metadata)

        # ì™„ë£Œ ë©”ì‹œì§€
        print("\n" + "="*50)
        print("âœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("="*50)
        print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print(f"   ğŸ¥ ë¹„ë””ì˜¤: {video_path}")
        print(f"   ğŸ“‹ ë©”íƒ€ì •ë³´: {metadata_path}")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€: {images_dir}")
        print(f"   ğŸ”Š ìŒì„±: {audio_path}")

        print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"   1. ë¹„ë””ì˜¤ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: {video_path}")
        print(f"   2. ìœ íŠœë¸Œì— ì—…ë¡œë“œí•˜ê³  ë©”íƒ€ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì œëª©/ì„¤ëª…/íƒœê·¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        print(f"   3. êµ¬ë…ì ì¦ê°€ë¥¼ ê¸°ëŒ€í•´ë³´ì„¸ìš”! ğŸ“ˆ\n")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
